{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T05:23:28.751520Z",
     "start_time": "2018-10-11T05:23:21.826926Z"
    }
   },
   "outputs": [],
   "source": [
    "#--Keras\n",
    "from keras import backend as K\n",
    "from keras import datasets, layers, models, optimizers, utils, initializers\n",
    "from keras import callbacks as cbks\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#--Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import functional_ops\n",
    "from tensorflow.python.client import device_lib\n",
    "#dataset modules\n",
    "from datasets.smallNORB import smallNORB #internal dependency\n",
    "#--Misc\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "from matplotlib import pyplot as plt, gridspec\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import functools\n",
    "from functools import partial\n",
    "import math\n",
    "\n",
    "#--CPU + GPU use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"0,1,2\" for \"cpu, gpu0, gpu1\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4) #40% of GPU memory\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) #set GPU\n",
    "\n",
    "#--List of available devices\n",
    "print('Devices:', device_lib.list_local_devices())\n",
    "#--Number of available devices\n",
    "n_devices= len(device_lib.list_local_devices())\n",
    "\n",
    "#--Fixing random state for reproducibility\n",
    "np.random.seed(10) \n",
    "\n",
    "#plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Definition of the model to train - Setting of the hyperparameters\n",
    "DATASET={\"name\": \"CIFAR10\", #MNIST , CIFAR10, smallNORB\n",
    "         \"train\": None, #Training dataset contrainer\n",
    "         \"test\": None, #Validation dataset contrainer\n",
    "         \"set\": \"test\",\n",
    "         \"param\":{\"target_scale\": [-1, 1],\n",
    "                  \"target_shape\": None, #None: will be automatically detected, (for mnist 28x28x1 cifar10 32x32x3 smallNORB 48x48x1)\n",
    "                  # do not combine extracting patches and resize\n",
    "                  \"target_patch\": None,# extract paches (mnist: None, cifar: 28,28 , smallnorb: 48,48) [H,W,number of patches]\n",
    "                  \"target_size\": None, # resize\n",
    "                  \"one_hot\": True # code the labels (if used)\n",
    "                 }\n",
    "        }\n",
    "\n",
    "GENERATOR= {\"name\":\"generator\",\n",
    "            \"train\": None, #Generator's model contrainer\n",
    "            \"param\":{\"topology\":\"ConvNet\",\n",
    "                     \"inputs_shape\": (100,), #noise dim\n",
    "                     \"output_shape\": None, #used later\n",
    "                     \"DeConvNet\":{\n",
    "                         \"optimizer\": Adam(lr=0.0002, beta_1=0.5),\n",
    "                         \"iters\": 1, # number of training iterations before/after training the discriminator\n",
    "                     }\n",
    "            }\n",
    "}\n",
    "DISCRIMINATOR={\"name\":\"discriminator\",\n",
    "            \"train\": None, #Discriminator's model contrainer\n",
    "            \"param\":{\"topology\":\"ConvNet\", #possible values: \"ConvNet\", \"Critic\", \"VCapsNet\", \"MCapsNet\"\n",
    "                     \"inputs_shape\":None, # will be defined after calling dataset \n",
    "                     \"output_shape\": None, # will be defined after calling dataset\n",
    "                     \n",
    "                     \"ConvNet\":{\"decoder\": None, # always None to be consistent with vcapsnet topology\n",
    "                                \"optimizer\": Adam(lr=0.0002, beta_1=0.5), \n",
    "                                \"iters\": 1, # number of training iterations before/after training the generator\n",
    "                               },\n",
    "                     \n",
    "                     \"Critic\":{\"decoder\": None, # always None to be consistent with vcapsnet topology\n",
    "                                \"optimizer\": RMSprop(lr=5e-5),\n",
    "                                \"iters\": 5, # number of training iterations before/after training the generator\n",
    "                               },\n",
    "                     \n",
    "                     \"VCapsNet\":{\n",
    "                                \"routing_iters\":3,\n",
    "                                \"decoder\":False, # turn on the decoder\n",
    "                                \"decoder_factor\": 0.0005,  #0.392\n",
    "                                \"L1_n\": 256,\n",
    "                                \"L2_n\": 32, #32 for mnist, 64 for cifar\n",
    "                                \"L2_dim\": 8,\n",
    "                                \"L3_dim\": 16,\n",
    "                                \"L4_n\": 512,\n",
    "                                \"L5_n\": 1024,\n",
    "                                \"optimizer\": Adam(lr=0.0002, beta_1=0.5),\n",
    "                                \"iters\": 1, # number of training iterations before/after training the generator\n",
    "                               },\n",
    "                     \n",
    "                     \"MCapsNet\":{\"routing_iters\":3,\n",
    "                                       \"decoder\": False,  # always None to be consistent with vcapsnet topology\n",
    "                                       \"L1_n\": 8,\n",
    "                                       \"L2_n\": 8, #8\n",
    "                                       \"L3_n\": 8, #16\n",
    "                                       \"L4_n\": 8, #16\n",
    "                                       \"pose_shape\": [4,4],\n",
    "                                       \"optimizer\": Adam(lr=0.0002, beta_1=0.5),\n",
    "                                       \"iters\": 1, # number of training iterations before/after training the generator\n",
    "                                      },\n",
    "                    }\n",
    "           }\n",
    "\n",
    "COMBINED={\"name\":\"gan\",\n",
    "          \"train\":None, #GAN's model contrainer\n",
    "          \"param\":{\"topology\": \"VCapsGAN\", # DCGAN, WGAN_GP, VCapsGAN, MCapsGAN\n",
    "                  },\n",
    "         }\n",
    "\n",
    "TRAIN={\n",
    "    #To train the discriminator only (as classifier), comment the line GENERATOR['name']:GENERATOR['train']\n",
    "    \"models_to_train\": {DISCRIMINATOR['name'] : DISCRIMINATOR['train'],\n",
    "                           GENERATOR['name']:GENERATOR['train'], \n",
    "                          },\n",
    "    # load weights from checkpoints\n",
    "    \"trained_models\":{'G':None, #'./ConvNet_GAN_CIFAR10_09-12_00-18/models/gen_ConvNet_Up.h5',\n",
    "                         'D':None, #'./ConvNet_GAN_CIFAR10_09-12_00-18/models/disc_VCapsNet.h5',\n",
    "                        },\n",
    "    # activate histograms in tensorboard\n",
    "    \"debug\": False,\n",
    "    \"param\":{\"batch_size\": 100, # the number of samples must be divisible by the batch size , mnist 60k cifar10 50k smallNORB 24.3k\n",
    "             \"epochs\": 100,\n",
    "             \"train_samples\": None, # will be defined after calling dataset\n",
    "             \"checkpoint\": {\"interval\":None,\n",
    "                            \"logdir\": \"./\",\n",
    "                            \"models\":{\"save\": True,\n",
    "                                     },\n",
    "                           }\n",
    "               }\n",
    "      }\n",
    "\n",
    "# Update the checkpoint log directory\n",
    "TRAIN[\"param\"][\"checkpoint\"][\"logdir\"] += DISCRIMINATOR[\"param\"][\"topology\"]+\"_\"\n",
    "if len(TRAIN[\"models_to_train\"]) == 2:\n",
    "    TRAIN[\"param\"][\"checkpoint\"][\"logdir\"] += \"GAN_\"\n",
    "else:\n",
    "    TRAIN[\"param\"][\"checkpoint\"][\"logdir\"] += \"classifier_\"\n",
    "TRAIN[\"param\"][\"checkpoint\"][\"logdir\"] += DATASET[\"name\"] +\"_\"+ datetime.now().strftime('%m-%d_%H-%M')+\"/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader ():\n",
    "    def __init__(self, set, name, target_shape=None, target_scale=None, target_patch=None, target_size=None, one_hot=False):\n",
    "        # Initialize attributes\n",
    "        self.name= name\n",
    "        self.target_shape= target_shape\n",
    "        self.target_scale= target_scale\n",
    "        self.target_patch= target_patch\n",
    "        self.target_size= target_size\n",
    "        self.one_hot = one_hot\n",
    "        self.set = set\n",
    "        # Load dataset\n",
    "        if self.name == 'MNIST':  self.load_MNIST()\n",
    "        if self.name == 'CIFAR10': self.load_CIFAR10()\n",
    "        if self.name == 'smallNORB': self.load_smallNORB()\n",
    "        self.imgs = np.array(self.imgs)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.n_samples=self.imgs.shape[0]\n",
    "        # Encode labels\n",
    "        if self.one_hot: self.labels=utils.to_categorical(self.labels, self.num_classes) \n",
    "        # Reshape dataset\n",
    "        if len(self.imgs.shape) == 3:\n",
    "            self.reshape((self.imgs.shape[1], self.imgs.shape[2], 1))\n",
    "        if self.target_shape:\n",
    "            self.reshape(self.target_shape)\n",
    "        self.img_shape=(self.imgs.shape[1], self.imgs.shape[2], self.imgs.shape[3])\n",
    "        # Scale values of images\n",
    "        if self.target_scale: self.rescale(self.target_scale)        \n",
    "        \n",
    "        print(\"{} {} dataset has been uploaded successfully \\n {} samples - shape: {}\".format(self.name, self.set, self.n_samples, self.img_shape))\n",
    "        \n",
    "    def reshape(self, target_shape):\n",
    "        self.imgs = self.imgs.reshape((self.n_samples,) + target_shape)\n",
    "        \n",
    "    def rescale(self, target_scale):\n",
    "        self.imgs = self.imgs.astype('float32') / (255/(target_scale[1]-target_scale[0])) + target_scale[0] #imgs in [rescale[0],rescale[1]]\n",
    "    \n",
    "    def patch (self, target_patch):\n",
    "        print(\"Extracting patches ...\")\n",
    "        imgs = [] ; labels = [];\n",
    "        for i in range(len(self.imgs)):\n",
    "            if len(self.imgs[0].shape) == 3:\n",
    "                if self.imgs[0].shape[2] == 1:\n",
    "                    x = extract_patches_2d(self.imgs[i, :, :, 0], (target_patch[0], target_patch[1]), max_patches=target_patch[2])\n",
    "                else:\n",
    "                    x = extract_patches_2d(self.imgs[i, :, :, :], (target_patch[0], target_patch[1]), max_patches=target_patch[2])\n",
    "            if len(self.imgs[0].shape) == 2:\n",
    "                x = extract_patches_2d(self.imgs[i], (target_patch[0], target_patch[1]), max_patches=target_patch[2])\n",
    "            y = np.full(target_patch[2], self.labels[i], dtype=int)\n",
    "            imgs.extend(x)\n",
    "            labels.extend(y)\n",
    "        print(\"Extraction finished!\")\n",
    "        return np.array(imgs), np.array(labels)\n",
    "    \n",
    "    def resize (self, target_size):\n",
    "        self.imgs = [cv2.resize(x, dsize=(target_size[0],target_size[1])) for x in self.imgs]\n",
    "    \n",
    "    def load_MNIST(self):\n",
    "        if self.set is 'train': (self.imgs, self.labels), (_,_) = datasets.mnist.load_data() # (imgs, labels): (60000x28x28 in [0,255], 60000x1 in [0,9]) (not onehot coded)\n",
    "        if self.set is 'test':  (_,_), (self.imgs, self.labels) = datasets.mnist.load_data() # (imgs, labels): (60000x28x28 in [0,255], 60000x1 in [0,9]) (not onehot coded)\n",
    "        self.num_classes= len(np.unique(self.labels, axis=0))\n",
    "        if self.target_size : self.resize(self.target_size)\n",
    "        if self.target_patch : self.imgs, self.labels = self.patch(self.target_patch)\n",
    "            \n",
    "    def load_CIFAR10(self):\n",
    "        if self.set is 'train': (self.imgs, self.labels), (_,_) = datasets.cifar10.load_data() # (imgs, labels): (50000x32x32x3 in [0,255], 50000x1 in [0,9]) (not onehot coded)\n",
    "        if self.set is 'test':  (_,_), (self.imgs, self.labels) = datasets.cifar10.load_data() # (imgs, labels): (50000x32x32x3 in [0,255], 50000x1 in [0,9]) (not onehot coded)\n",
    "        self.num_classes= len(np.unique(self.labels, axis=0))\n",
    "        if self.target_size : self.resize(self.target_size)\n",
    "        if self.target_patch : self.imgs, self.labels = self.patch(self.target_patch)\n",
    "            \n",
    "    def load_smallNORB(self):\n",
    "        if self.target_patch:\n",
    "            imgs_file_name = 'smallNorb_'+self.set+'_imgs_patches_'+str(self.target_patch[0])+'_'+str(self.target_patch[1])+'.npy'\n",
    "            labels_file_name = 'smallNorb_'+self.set+'_labels_patches_'+str(self.target_patch[0])+'_'+str(self.target_patch[1])+'.npy'\n",
    "        elif self.target_size:\n",
    "            imgs_file_name = 'smallNorb_'+self.set+'_imgs_resized_'+str(self.target_size[0])+'_'+str(self.target_size[1])+'.npy'\n",
    "            labels_file_name = 'smallNorb_'+self.set+'_labels_resized_'+str(self.target_size[0])+'_'+str(self.target_size[1])+'.npy'\n",
    "        else :\n",
    "            imgs_file_name = 'smallNorb_'+self.set+'_imgs.npy'\n",
    "            labels_file_name = 'smallNorb_'+self.set+'_labels.npy'\n",
    "        if not os.path.exists(os.path.join('datasets', imgs_file_name)) or not os.path.exists(os.path.join('datasets', labels_file_name)):\n",
    "            if not os.path.exists(os.path.join('datasets', 'smallNorb_'+self.set+'_imgs.npy')) or not os.path.exists(os.path.join('datasets', 'smallNorb_'+self.set+'_labels.npy')):\n",
    "                (self.imgs, _ , self.labels, _) = smallNORB(dataset_dir='datasets', set=self.set).load_data() # (imgs, labels): (60000x32x32x3 in [0,255], 60000x1 in [0,9]) (not onehot coded)\n",
    "                np.save(os.path.join('datasets', 'smallNorb_'+self.set+'_imgs.npy'), self.imgs)\n",
    "                np.save(os.path.join('datasets', 'smallNorb_'+self.set+'_labels.npy'), self.labels)\n",
    "            else:\n",
    "                self.imgs = np.load (os.path.join('datasets','smallNorb_'+self.set+'_imgs.npy'))\n",
    "                self.labels = np.load (os.path.join('datasets','smallNorb_'+self.set+'_labels.npy'))\n",
    "            if self.target_size : self.resize(self.target_size)\n",
    "            if self.target_patch: self.imgs , self.labels = self.patch(self.target_patch)\n",
    "            if not os.path.exists(os.path.join('datasets', imgs_file_name)):\n",
    "                np.save(os.path.join('datasets', imgs_file_name), self.imgs)\n",
    "            else:\n",
    "                self.imgs = np.load (os.path.join('datasets',imgs_file_name))\n",
    "            if not os.path.exists(os.path.join('datasets', labels_file_name)):\n",
    "                np.save(os.path.join('datasets', labels_file_name), self.labels)\n",
    "            else:\n",
    "                self.labels = np.load (os.path.join('datasets',labels_file_name))\n",
    "        else:\n",
    "            self.imgs = np.load (os.path.join('datasets',imgs_file_name))\n",
    "            self.labels = np.load (os.path.join('datasets',labels_file_name))\n",
    "        self.num_classes= len(np.unique(self.labels, axis=0))\n",
    "        \n",
    "    '''def next_batch(self, batch_size):\n",
    "        idx = np.arange(0 , len(self.imgs))\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:batch_size]\n",
    "        data_shuffle = [self.imgs[ i] for i in idx]\n",
    "        labels_shuffle = [self.labels[ i] for i in idx]\n",
    "        return np.asarray(data_shuffle), np.asarray(labels_shuffle)'''\n",
    "    \n",
    "    def plot_samples(self, grid=[10,10], imgsize=[8,8], logdir=None):\n",
    "        imgs=self.imgs\n",
    "        img_range=self.target_scale\n",
    "        cmap=(None if (self.imgs.shape[-1]) == 3 else 'gray')\n",
    "        # Get random samples\n",
    "        imgs= imgs[0:grid[0]*grid[1]]\n",
    "        if cmap is 'gray': imgs = np.squeeze(imgs, -1)\n",
    "        if np.shape(imgs)[0] is 1: imgs = np.squeeze(imgs, 0)\n",
    "        imgs = ((imgs-img_range[0])*255/(img_range[1]-img_range[0])).astype(np.uint8)\n",
    "        # Create a figure object\n",
    "        fig= plt.figure(figsize=(imgsize[0], imgsize[1]))\n",
    "        # Show images\n",
    "        for i in range(0, grid[0]*grid[1]):        \n",
    "            fig.add_subplot(grid[0], grid[1], i+1)\n",
    "            img = imgs[i]\n",
    "            plt.imshow(img, cmap=cmap)\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        if logdir: fig.savefig(os.path.join(logdir, self.name+'.png'))\n",
    "            \n",
    "    def inception_score(self, splits=10):\n",
    "        imgs = self.imgs\n",
    "        if (len(np.shape(imgs))==3 or np.shape(imgs)[-1]==1):\n",
    "            imgs = np.squeeze(imgs)\n",
    "            imgs = np.stack((imgs,)*3, -1)\n",
    "        imgs = np.rollaxis(imgs, 3, 1)  \n",
    "        session = tf.InteractiveSession()\n",
    "        BATCH_SIZE=64\n",
    "        # Run images through Inception.\n",
    "        inception_images=tf.placeholder(tf.float32,[BATCH_SIZE,3,None,None])\n",
    "        def inception_logits(images=inception_images, num_splits=1):\n",
    "            images=tf.transpose(images,[0,2,3,1])\n",
    "            size = 299\n",
    "            images = tf.image.resize_bilinear(images, [size, size])\n",
    "            generated_images_list = array_ops.split(\n",
    "            images, num_or_size_splits=num_splits)\n",
    "            logits = functional_ops.map_fn(\n",
    "                fn=functools.partial(tf.contrib.gan.eval.run_inception, output_tensor='logits:0'),\n",
    "                elems=array_ops.stack(generated_images_list),\n",
    "                parallel_iterations=1,\n",
    "                back_prop=False,\n",
    "                swap_memory=True,\n",
    "                name='RunClassifier')\n",
    "            logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
    "            return logits\n",
    "\n",
    "        logits=inception_logits()\n",
    "\n",
    "        def get_inception_probs(inps):\n",
    "            preds = []\n",
    "            n_batches = len(inps)//BATCH_SIZE\n",
    "            for i in range(n_batches):\n",
    "                inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "                pred = logits.eval({inception_images:inp})[:,:1000]\n",
    "                preds.append(pred)\n",
    "            preds = np.concatenate(preds, 0)\n",
    "            preds=np.exp(preds)/np.sum(np.exp(preds),1,keepdims=True)\n",
    "            return preds\n",
    "\n",
    "        def preds2score(preds,splits):\n",
    "            scores = []\n",
    "            for i in range(splits):\n",
    "                part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
    "                kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "                kl = np.mean(np.sum(kl, 1))\n",
    "                scores.append(np.exp(kl))\n",
    "            return np.mean(scores), np.std(scores)\n",
    "\n",
    "        def get_inception_score(images, splits):\n",
    "            assert(type(images) == np.ndarray)\n",
    "            assert(len(images.shape)==4)\n",
    "            assert(images.shape[1]==3)\n",
    "            assert(np.max(images[0])<=1)\n",
    "            assert(np.min(images[0])>=-1)\n",
    "            preds=get_inception_probs(images)\n",
    "            print ('Inception Score for %i samples in %i splits'% (preds.shape[0],splits))\n",
    "            mean,std = preds2score(preds,splits)\n",
    "            return mean,std  # Reference values: 11.34 for 49984 CIFAR-10 training set images, or mean=11.31, std=0.08 if in 10 splits (default).\n",
    "        score = get_inception_score(imgs, splits)\n",
    "        tf.InteractiveSession.close(session)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "DATASET[\"train\"] = DataLoader('train', DATASET[\"name\"], DATASET[\"param\"][\"target_shape\"], DATASET[\"param\"][\"target_scale\"], DATASET[\"param\"][\"target_patch\"], DATASET[\"param\"][\"target_size\"], DATASET[\"param\"][\"one_hot\"])\n",
    "DATASET[\"test\"] = DataLoader('test', DATASET[\"name\"], DATASET[\"param\"][\"target_shape\"], DATASET[\"param\"][\"target_scale\"], DATASET[\"param\"][\"target_patch\"], DATASET[\"param\"][\"target_size\"], DATASET[\"param\"][\"one_hot\"])\n",
    "# Update the containers defined in the dictionary\n",
    "TRAIN[\"param\"][\"train_samples\"]= DATASET[\"train\"].n_samples\n",
    "if DATASET[\"param\"][\"target_scale\"] is None: DATASET[\"param\"][\"target_scale\"]= [0, 255]\n",
    "if DISCRIMINATOR[\"param\"][\"inputs_shape\"] is None: DISCRIMINATOR[\"param\"][\"inputs_shape\"]= DATASET[\"train\"].img_shape\n",
    "if DISCRIMINATOR[\"param\"][\"output_shape\"] is None:\n",
    "    if len(TRAIN[\"models_to_train\"]) == 2:\n",
    "        DISCRIMINATOR[\"param\"][\"output_shape\"]= (2,)\n",
    "    else:\n",
    "        DISCRIMINATOR[\"param\"][\"output_shape\"]= (DATASET[\"train\"].num_classes,)\n",
    "\n",
    "if GENERATOR[\"param\"][\"output_shape\"] is None: GENERATOR[\"param\"][\"output_shape\"]= DATASET[\"train\"].img_shape\n",
    "\n",
    "# Create checkpoint log directory\n",
    "if not os.path.exists(TRAIN[\"param\"][\"checkpoint\"][\"logdir\"]): os.makedirs(TRAIN[\"param\"][\"checkpoint\"][\"logdir\"])\n",
    "\n",
    "# Plot random samples\n",
    "DATASET[\"train\"].plot_samples(grid=[10,10], imgsize=[10,10], logdir=TRAIN[\"param\"][\"checkpoint\"][\"logdir\"])\n",
    "# Compute the Inception score of the dataset\n",
    "dataset_inception_score = DATASET[\"train\"].inception_score()\n",
    "print(\"IS: mean {}, stdv {}\".format(dataset_inception_score[0], dataset_inception_score[1]))\n",
    "assert DATASET[\"train\"].n_samples % TRAIN[\"param\"][\"batch_size\"] == 0, \"number of samples must be divisible by the batch size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if len(TRAIN[\"models_to_train\"]) == 2: # if training a GAN\n",
    "    def generator_sampler(latent_dim, generator, n_images):\n",
    "        def sampler():\n",
    "            gen_dict = GENERATOR[\"param\"]\n",
    "            zsamples = np.random.normal(size=(n_images[0]*n_images[1], latent_dim))\n",
    "            gen = imgs_utils.dim_ordering_unfix(generator.predict(zsamples)).transpose((0, 2, 3, 1))\n",
    "            if len (gen_dict[\"output_shape\"]) == 3:\n",
    "                if gen_dict[\"output_shape\"][2] == 1:\n",
    "                    img_shape=gen_dict[\"output_shape\"][:2]\n",
    "                else:\n",
    "                    img_shape= gen_dict[\"output_shape\"]\n",
    "            else:\n",
    "                img_shape=gen_dict[\"output_shape\"]\n",
    "                \n",
    "            return gen.reshape((n_images[0],n_images[1],)+ img_shape)\n",
    "        return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Squash function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$squash(\\mathbf{s}) = \\frac{\\| \\mathbf{s} \\|^2}{1+ \\| \\mathbf{s} \\|^2} \\frac{\\mathbf{s}}{\\| \\mathbf{s} \\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def squash(inputs, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(inputs), axis, keepdims=True)\n",
    "    scale = (s_squared_norm / (1 + s_squared_norm))\n",
    "    return scale * inputs / K.sqrt(s_squared_norm + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Margin loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L} = \\sum_i y_{true, i} \\max(0, m^+ - y_{pred, i})^2 + \\lambda (1-y_{true, i}) \\max (0, y_{pred, i} - m^-)^2 $$\n",
    "where $\\mathbf{y}_{pred, i} = \\| \\mathbf{v}_i \\| \\, , \\, m^+ = 0.9 \\, , \\, m^- = 0.1 \\, \\text{and} \\, \\lambda = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spread loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}=  \\sum_i max(0, margin - (y_{pred\\_true, i}-y_{pred\\_false, i}))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossentropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator tries to minimize the cross entropy (information distance) between the prediction of Discriminator given a generated sample and a valid prediction $\\Rightarrow$ goal: fool the Discriminator  <br> \n",
    "\\begin{align} G =&\\underset{G}{\\operatorname{argmin}} \\mathcal{H}(y_{true} = 1, y_{pred} = D(G(\\textbf{z}^{(i)})))\\\\=&\\underset{G}{\\operatorname{argmax}} \\mathcal{H}(y_{true} = 0, y_{pred} = D(G(\\textbf{z}^{(i)})))\\\\=&\\underset{G}{\\operatorname{argmax}} \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [-log(1-D(G(\\textbf{z}^{(i)}))] \\\\=&\\underset{G}{\\operatorname{argmin}} \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [log(1-D(G(\\textbf{z}^{(i)}))] \\\\=&\\underset{G}{\\operatorname{argmin}}  \\sum_{i}log(1- D(G(\\textbf{z}^{(i)}))) \\end{align}\n",
    "\n",
    "The margin loss $L_M$ is an empirical loss function that worked very well in the CapsNet und is also introduced in the CapsGAN: <br>\n",
    "\n",
    "\\begin{align} \\mathcal{L}_M(y_{true}, y_{pred}) = \\sum_{k=1}^K y_{true} max (0,m^+-y_{pred})^2+\\lambda(1-y_{true})max(0,y_{pred}-m^-)^2\\end{align}<br><br>\n",
    "$K$: number  of classes (here $K$=2)\n",
    "\n",
    "$L_M$ can be also interpreted as a probability density distance measurement, thus:<br>\n",
    "\\begin{align}G=&\\underset{G}{\\operatorname{argmin}} \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [\\mathcal{L}_M(y_{true}=1,y_{pred}=D(G(\\textbf{z})))]\\\\ =&\\underset{G}{\\operatorname{argmin}}  \\sum_i  max (0,m^+-D(G(\\textbf{z}^{(i)})))^2\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator tries to minimize the cross entropy between its prediction given a generated sample and a fake prediction. \t\n",
    "At the same time, it tries to minimize the cross entropy between its prediction given a real sample and a valid prediction.<br>\n",
    "$\\Rightarrow$ Improve the classification\n",
    "\n",
    "\\begin{align}D =&\\underset{D}{\\operatorname{argmin}} \\mathcal{H}(y_{true} = [1,0], y_{pred} = [D(\\textbf{x}^{(i)}), D(G(\\textbf{z}^{(i)}))]) \\\\=&\\underset{D}{\\operatorname{argmin}}  - \\mathop{\\mathbb{E}}_{\\textbf{x}^{(i)} \\sim p_{data}(\\textbf{x}^{(i)})} [log(D(\\textbf{x}^{(i)})) ] - \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [log (1-D(G(\\textbf{z}^{(i)}))]\\\\=&\\underset{D}{\\operatorname{argmax}}\\mathop{\\mathbb{E}}_{\\textbf{x}^{(i)} \\sim p_{data}(\\textbf{x}^{(i)})} [log(D(\\textbf{x}^{(i)})) ] + \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [log (1-D(G(\\textbf{z}^{(i)}))] \\\\=&\\underset{D}{\\operatorname{argmax}} \\sum_{i}log (D(\\textbf{x}^{(i)})) + log(1-D(G(\\textbf{z}^{(i)})))\\end{align}\n",
    "<br>\n",
    "The margin loss $\\mathcal{L}_M$ is an empirical loss function that worked very well in the CapsNet und is also introduced in the CapsGAN: <br>\n",
    "\n",
    "\\begin{align} \\mathcal{L}_M(y_{true}, y_{pred}) = \\sum_{k=1}^K y_{true} max (0,m^+-y_{pred})^2+\\lambda(1-y_{true})max(0,y_{pred}-m^-)^2\\end{align}<br><br>\n",
    "$K$: number  of classes (here $K$=2)\n",
    "\n",
    "$L_M$ can be also interpreted as a probability density distance measurement, thus:<br>\n",
    "\\begin{align}D=&\\underset{D}{\\operatorname{argmin}} \\mathop{\\mathbb{E}}_{\\textbf{z}^{(i)} \\sim p_z(\\textbf{z}^{(i)})} [\\mathcal{L}_M(y_{true}= [1,0] , y_{pred}=[D(\\textbf{x}^{(i)}),D(G(\\textbf{z}^{(i)}))])] \\\\=&\\underset{G}{\\operatorname{argmin}}  \\sum_i max (0,m^+-D(\\textbf{x}^{(i)}))^2 + \\lambda max (0,D(G(\\textbf{z}^{(i)})-m^-)^2\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient penalty loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, name='generator', **kwargs):\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.input_shape = None\n",
    "        self.output_shape = None\n",
    "        \n",
    "    def build(self, input_shape, output_shape, len_io):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.sequential = self.build_sequential(input_shape, output_shape)\n",
    "        self.sequential.name = 'generator'\n",
    "        \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for i in range(len_io):\n",
    "            inputs += [layers.Input(shape=input_shape, name='img'+str(i+1)),]\n",
    "            outputs += [self.sequential(inputs[i]),]\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs,\n",
    "                            outputs=outputs)\n",
    "        self.model.name = 'generator_in_gan'\n",
    "        print(\"************************************GENERATOR*************************************\")\n",
    "        self.sequential.summary()\n",
    "        return self.model\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        self.model.compile(**kwargs)\n",
    "        print(self.name, \"compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConvNet_Up(Generator):\n",
    "    def __init__ (self, name='ConvNet_Up', **kwargs):\n",
    "        super(ConvNet_Up, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "    def build_sequential(self, input_shape, output_shape):\n",
    "\n",
    "        # input layer\n",
    "        inputs=layers.Input(shape=input_shape)\n",
    "        x = layers.Dense(256 * output_shape[0]//4 * output_shape[1]//4, use_bias=False, kernel_initializer=initializers.RandomNormal(0, 0.02))(inputs)\n",
    "        x = layers.Reshape((output_shape[0]//4 , output_shape[1]//4 , 256))(x)\n",
    "        x = layers.BatchNormalization(momentum=0.9, gamma_initializer=initializers.RandomNormal(1, 0.02))(x, training=1)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.UpSampling2D()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=4, padding=\"same\", use_bias=False, kernel_initializer=initializers.RandomNormal(0, 0.02))(x)\n",
    "        x = layers.BatchNormalization(momentum=0.9, gamma_initializer=initializers.RandomNormal(1, 0.02))(x, training=1)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.UpSampling2D()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=4, padding=\"same\", use_bias=False, kernel_initializer=initializers.RandomNormal(0, 0.02))(x)\n",
    "        x = layers.BatchNormalization(momentum=0.9, gamma_initializer=initializers.RandomNormal(1, 0.02))(x, training=1)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(output_shape[-1], kernel_size=4, padding=\"same\", use_bias=False, kernel_initializer=initializers.RandomNormal(0, 0.02))(x)\n",
    "        gen_out = layers.Activation(\"tanh\")(x)\n",
    "        \n",
    "        return models.Model(inputs, gen_out)\n",
    "    \n",
    "    def cross_entropy_loss(y_true, y_pred):\n",
    "        loss = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "            0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "        return K.mean(K.sum(loss, 1))\n",
    "    \n",
    "    def compile(self, optimizer=None, **kwargs):\n",
    "        if optimizer is None: optimizer = 'binary_crossentropy'\n",
    "        super(ConvNet_Up, self).compile(optimizer=optimizer, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, name='Discriminator', **kwargs):\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.input_shape = None\n",
    "        self.output_shape = None\n",
    "        self.decoder = None\n",
    "            \n",
    "    def build(self, input_shape, output_shape, len_io=1, **kwargs):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if hasattr(output_shape, \"__len__\"): output_shape = np.prod(output_shape)\n",
    "        \n",
    "        self.sequential = self.build_sequential(input_shape, output_shape, **kwargs)\n",
    "        self.sequential.name = 'discriminator'\n",
    "        print(\"************************************DISCRIMINATOR*************************************\")\n",
    "        self.sequential.summary()\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        if len(device_lib.list_local_devices()) >= 3:\n",
    "            self.sequential = multi_gpu_model(self.sequential, gpus=len(device_lib.list_local_devices())-1)\n",
    "        for i in range(len_io):\n",
    "            inputs += [layers.Input(shape=input_shape, name='img'+str(i+1)),]\n",
    "            outputs += [self.sequential(inputs[i]),]\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs,\n",
    "                            outputs=outputs)\n",
    "        self.model.name = 'discriminator_in_gan'\n",
    "        print(\"************************************DISCRIMINATOR_IN_GAN*************************************\")\n",
    "        self.model.summary()\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        self.model.compile(**kwargs)\n",
    "        print(self.name, \"compiled\")\n",
    "        \n",
    "    def train_generator(self, x, y, shift_fraction=0.):\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, y, batch_size=self.batch_size)\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            if self.decoder : yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "            else: yield (x_batch,y_batch)\n",
    "                \n",
    "    def test_generator(self, x, y):\n",
    "        if self.decoder : return ([x, y], [y, x])\n",
    "        else: return (x, y)\n",
    "    \n",
    "    def fit(self, x, y, batch_size, epochs, callbacks=[], load_weights=None, validation_data=None, PlotModel=True, TensorBoard=True, debug=False, ModelCheckpoint= True, CSVLogger=True, logdir='./', **kwargs):\n",
    "        cb = []\n",
    "        cb += callbacks\n",
    "        self.batch_size= batch_size\n",
    "        if CSVLogger: cb.append(cbks.CSVLogger(os.path.join(logdir, 'history.csv')))\n",
    "        if TensorBoard: cb.append(cbks.TensorBoard(log_dir=os.path.join(logdir, 'tb'),\n",
    "                                   batch_size=self.batch_size, histogram_freq=debug))\n",
    "        if ModelCheckpoint:\n",
    "            if not os.path.exists(os.path.join(logdir, 'models')): os.makedirs(os.path.join(logdir, 'models'))\n",
    "            cb.append(cbks.ModelCheckpoint(os.path.join(logdir, 'models/discriminator.h5'),\n",
    "                                                        save_best_only=False, save_weights_only=True, verbose=1))\n",
    "        if PlotModel: plot_model(self.model, to_file=os.path.join(logdir, self.name+'.svg'), show_shapes=True)\n",
    "        if load_weights : self.model.load_weights(load_weights)\n",
    "        self.model.fit_generator(generator=self.train_generator(x, y, 0.1),\n",
    "                                  steps_per_epoch=int(x.shape[0] / batch_size),\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=self.test_generator(validation_data[0], validation_data[1]),\n",
    "                                  callbacks= cb,\n",
    "                                   **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(Discriminator):\n",
    "    def __init__ (self, name='ConvNet', **kwargs):\n",
    "        super(ConvNet, self).__init__(name=name, **kwargs)\n",
    "    \n",
    "    def build_sequential(self, input_shape, output_shape): \n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if hasattr(output_shape, \"__len__\"): output_shape = np.prod(output_shape)\n",
    "        \n",
    "        # . -> D(.)\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        #conv layer\n",
    "        seq=layers.Conv2D(64, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(inputs)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "        \n",
    "        #conv layer\n",
    "        seq=layers.Conv2D(128, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        seq=layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(seq, training=1)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "        \n",
    "        seq=layers.Conv2D(256, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        seq=layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(seq, training=1)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "        \n",
    "        seq=layers.Conv2D(2, kernel_size=seq.get_shape().as_list()[1] , strides=1, use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        \n",
    "        seq=layers.Flatten()(seq)\n",
    "        output = layers.Activation('sigmoid')(seq)\n",
    "        m = models.Model(inputs, output)\n",
    "        return m\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred):\n",
    "        loss = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "            0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "        return K.mean(K.sum(loss, 1))\n",
    "    \n",
    "    def compile(self, optimizer=None, **kwargs):\n",
    "        if optimizer is None: optimizer = self.loss_fn\n",
    "        super(ConvNet, self).compile(optimizer=optimizer, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ConvNet Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConvNet_Critic(Discriminator):\n",
    "    def __init__ (self, batch_size, name='ConvNet', **kwargs):\n",
    "        super(ConvNet_Critic, self).__init__(name=name, **kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        print(\"batch_size\", self.batch_size)\n",
    "        \n",
    "    def build_sequential(self, input_shape, output_shape): \n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if hasattr(output_shape, \"__len__\"): output_shape = np.prod(output_shape)\n",
    "        \n",
    "        # . -> D(.)\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        #conv layer\n",
    "        seq=layers.Conv2D(64, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(inputs)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "\n",
    "        #conv layer\n",
    "        seq=layers.Conv2D(128, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        #seq=layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(seq, training=1)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "        \n",
    "        seq=layers.Conv2D(256, kernel_size=4, strides=2, padding='same', use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        #seq=layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(seq, training=1)\n",
    "        seq=layers.LeakyReLU(alpha=0.2)(seq)\n",
    "        \n",
    "        seq=layers.Conv2D(2, kernel_size=seq.get_shape().as_list()[1], strides=1, use_bias=False, kernel_initializer=initializers.RandomNormal(0,0.02))(seq)\n",
    "        \n",
    "        output=layers.Flatten()(seq)\n",
    "        m = models.Model(inputs, output)\n",
    "        return m\n",
    "    \n",
    "    def build(self, input_shape, output_shape, len_io=1, **kwargs):\n",
    "        \n",
    "        class RandomWeightedAverage(layers.merge._Merge):\n",
    "            def __init__(self, batch_size, **kwargs):\n",
    "                self.batch_size = batch_size\n",
    "                super(RandomWeightedAverage, self).__init__(**kwargs)\n",
    "            \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "            def _merge_function(self, inputs):\n",
    "                alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
    "                return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if hasattr(output_shape, \"__len__\"): output_shape = np.prod(output_shape)\n",
    "        \n",
    "        self.sequential = self.build_sequential(input_shape, output_shape, **kwargs)\n",
    "        \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        x = layers.Input(shape=input_shape)\n",
    "        G_z = layers.Input(shape=input_shape)\n",
    "        D_x = self.sequential(x)\n",
    "        D_G_z = self.sequential(G_z)\n",
    "        \n",
    "        interpolated_img = RandomWeightedAverage(self.batch_size)([x, G_z])\n",
    "        validity_interpolated = self.sequential(interpolated_img)\n",
    "        self.partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        \n",
    "        self.partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "        \n",
    "        inputs = [x, G_z]\n",
    "        outputs = [D_x, D_G_z, validity_interpolated]\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs,\n",
    "                                  outputs=outputs)\n",
    "        \n",
    "        self.model.summary()\n",
    "        return self.model\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "    \n",
    "    def compile(self, loss, **kwargs):\n",
    "        loss.append(self.partial_gp_loss)\n",
    "        super(ConvNet_Critic, self).compile(loss=loss, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### VCapsNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "VCapsNet Inspired by https://github.com/XifengGuo/CapsNet-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ParentCaps(layers.Layer):\n",
    "    def __init__(self, n_caps, dim_caps, routing_iters,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(ParentCaps, self).__init__(**kwargs)\n",
    "        self.n_caps = n_caps\n",
    "        self.dim = dim_caps\n",
    "        self.routing_iters = routing_iters\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, n_caps_in, dim_im]\"\n",
    "        self.n_caps_in = input_shape[1]\n",
    "        self.dim_im = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.n_caps, self.n_caps_in,\n",
    "                                        self.dim, self.dim_im],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs_hat = self.spatial_transform(inputs)\n",
    "        outputs = self.routing(inputs_hat)\n",
    "        return outputs\n",
    "\n",
    "    def spatial_transform(self, inputs):\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.n_caps, 1, 1])\n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "        return inputs_hat\n",
    "\n",
    "    def routing(self, inputs_hat):    \n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.n_caps, self.n_caps_in])\n",
    "        for i in range(self.routing_iters):\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "            #outputs = layers.advanced_activations.LeakyReLU(alpha=0.2)(K.batch_dot(c, inputs_hat, [2, 2]))\n",
    "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))\n",
    "            if i < self.routing_iters - 1:\n",
    "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "        return outputs #layers.advanced_activations.LeakyReLU()(outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.n_caps, self.dim])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'n_caps': self.n_caps,\n",
    "            'dim': self.dim,\n",
    "            'routings': self.routing_iters\n",
    "        }\n",
    "        base_config = super(ParentCaps, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:\n",
    "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
    "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
    "        return masked\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VCapsNet(Discriminator):\n",
    "    def __init__ (self, name='VCapsNet', **kwargs):\n",
    "        super(VCapsNet, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "    def build_sequential(self, input_shape, output_shape, L1_n, L2_n, L2_dim, L3_dim, routing=3, decoder=False, L4_n=512, L5_n=1024): #L3_n is the same as output_shape\n",
    "        self.decoder = decoder\n",
    "        # Input\n",
    "        imgs = layers.Input(shape=input_shape)\n",
    "        # Conv layer\n",
    "        x = layers.Conv2D(filters=L1_n, kernel_size=9, strides=1, kernel_initializer=initializers.RandomNormal(0,0.02), padding='valid', name='conv1')(imgs)\n",
    "        x = layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        #x = layers.Conv2D(filters=L1_n, kernel_size=9, strides=1, kernel_initializer=initializers.RandomNormal(0,0.02), padding='same', name='conv2')(x)\n",
    "        #x = layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(x)\n",
    "        #x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        #x = layers.Conv2D(filters=L1_n, kernel_size=9, strides=1, kernel_initializer=initializers.RandomNormal(0,0.02), padding='same', name='conv3')(x)\n",
    "        #x = layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(x)\n",
    "        #x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        # [None, num_capsule, dim_capsule]\n",
    "        x = self.PrimaryCaps(x, dim_caps=L2_dim, n_channels=L2_n, kernel_size=9, strides=2, padding='valid')\n",
    "        # routing algo\n",
    "        digitcaps = ParentCaps(n_caps=output_shape, dim_caps=L3_dim, routing_iters=routing, kernel_initializer=initializers.RandomNormal(0,0.02), name=\"ParentCaps_\")(x)\n",
    "        # This is an auxiliary layer to replace each capsule with its length to match the true label's shape.\n",
    "        pred = Length(name=\"capsnet\")(digitcaps)\n",
    "        if decoder:\n",
    "            # Decoder network\n",
    "            labels = layers.Input(shape=(output_shape,))\n",
    "            masked_by_labels = Mask()([digitcaps, labels])  # The true label is used to mask the output of capsule layer. For training\n",
    "            masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "            decoder = models.Sequential(name='decoder')\n",
    "            decoder.add(layers.Dense(L4_n, activation='relu', input_dim=output_shape*L3_dim))\n",
    "            decoder.add(layers.Dense(L5_n, activation='relu'))\n",
    "            decoder.add(layers.Dense(np.prod(disc_dict[\"inputs_shape\"]), activation='tanh', name=\"Disc_L5_Decoder_FC3\"))\n",
    "            decoder.add(layers.Reshape(target_shape=disc_dict[\"inputs_shape\"], name='decoder'))\n",
    "            # Models for training and evaluation (prediction)\n",
    "            return models.Model([imgs, labels], [pred, decoder(masked_by_labels)])\n",
    "            #eval_model = models.Model(imgs, [pred, decoder(masked)])\n",
    "        else:\n",
    "            return models.Model(imgs, pred)\n",
    "    \n",
    "    def PrimaryCaps(self, inputs, dim_caps, n_channels, kernel_size, strides, padding):\n",
    "        output = layers.Conv2D(filters=dim_caps*n_channels, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=initializers.RandomNormal(0,0.02))(inputs)\n",
    "        output = layers.Reshape(target_shape=[-1, dim_caps])(output)\n",
    "        output = layers.BatchNormalization(momentum=0.9, epsilon=1.01e-5, gamma_initializer=initializers.RandomNormal(1,0.02))(output)\n",
    "        #output = layers.LeakyReLU(alpha=0.2)(output)\n",
    "        output = layers.Lambda(squash)(output)\n",
    "        return output\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred):\n",
    "        loss = y_true * K.square(K.maximum(0., 0.9 - y_pred)) +  0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "        return K.mean(K.sum(loss, 1))\n",
    "    \n",
    "    def compile(self, optimizer=None, **kwargs):\n",
    "        if optimizer is None: optimizer = self.loss_fn\n",
    "        super(VCapsNet, self).compile(optimizer=optimizer, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(layers.Layer):\n",
    "    def __init__(self, n_caps_out, pose_shape, kernel_size=None, strides=None, routing_iters=3, trainable=True, name=None, **kwargs):\n",
    "        self.n_caps_out = n_caps_out\n",
    "        self.pose_shape = pose_shape \n",
    "        self.routing_iters = routing_iters\n",
    "        self.strides = strides\n",
    "        if kernel_size: # in case conv capsules\n",
    "            self.kernel_size= kernel_size\n",
    "            self.spatial_dim = [1, 1]\n",
    "        else: # in case class capsules\n",
    "            self.kernel_size = [1, 1]\n",
    "            self.spatial_dim = []\n",
    "        super(CapsLayer, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.pose_shape_in = [int(np.sqrt(input_shape[-1]-1)),int(np.sqrt(input_shape[-1]-1))]\n",
    "        self.n_caps_in = input_shape[-2]\n",
    "        self.spatial_size_in=[int(input_shape[1]), int(input_shape[2])]\n",
    "        self.spatial_size=self.spatial_size_in\n",
    "        # beta_v: SHAPE=[1, (1, 1,) 1, O, 1], TYPE=tensor, VALUE= trainable parameter (vector of dim: # capsules in layer L+1)\n",
    "        self.beta_v = self.add_weight(shape=[1,] + self.spatial_dim +[1, self.n_caps_out, 1],\n",
    "                                    initializer=initializers.glorot_normal(),\n",
    "                                    name='beta_v')\n",
    "        # beta_a: SHAPE=[1, (1, 1,) 1, O, 1], TYPE=tensor, VALUE= trainable parameter (vector of dim: # capsules in layer L+1)b, s, s, k, k, 1, B, p, p\n",
    "        self.beta_a = self.add_weight(shape=[1,] + self.spatial_dim +[1, self.n_caps_out, 1],\n",
    "                                    initializer=initializers.glorot_normal(),\n",
    "                                    name='beta_a')\n",
    "        # W_ij: SHAPE=[1, 1, 1, (k0*k1*)I, O, p0, p1]\n",
    "        self.W_ij = self.add_weight(shape=[1, 1, 1, self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in, self.n_caps_out, self.pose_shape[0], self.pose_shape[1]],\n",
    "                                    initializer=initializers.RandomNormal(mean=0.0, stddev=0.05),\n",
    "                                  name='W_ij') #vll. hier die 1 durch size_batch ersetzen\n",
    "        # run build method with __init__\n",
    "        self.built = True \n",
    "        super(CapsLayer, self).build(input_shape)\n",
    "    def call(self, inputs):\n",
    "        self.batch_size = K.shape(inputs)[0]\n",
    "        ################ inputs ################\n",
    "        # M_i:SHAPE=[b, s0, s1, I, p0*p1], TYPE= tensor, VALUE= pose matrix\n",
    "        # a_i:SHAPE=[b, s0, s1, I], TYPE= tensor, VALUE= activations\n",
    "        M_i = inputs[:,:,:,:,:16]\n",
    "        a_i = inputs[:,:,:,:,16]\n",
    "\n",
    "        M_i= K.reshape(M_i, shape=[-1, self.spatial_size[0], self.spatial_size[1], self.n_caps_in, self.pose_shape_in[0],self.pose_shape_in[1]])\n",
    "        ################ depthwise conv ################\n",
    "        # M_i:SHAPE=[b, s0', s1', (k0*k1*)I, p0*p1], TYPE= tensor, VALUE= pose matrix\n",
    "        # a_i:SHAPE=[b, s0', s1', (k0*k1*)I], TYPE= tensor, VALUE= activations\n",
    "        if len(self.spatial_dim): M_i, a_i = self.depthwise_conv(M_i, a_i)\n",
    "        ################ spatial tansformation ################\n",
    "        # V_ij: SHAPE=[b, s0', s1', (k0*k1*)I, O, p0, p1], TYPE= tensor, VALUE= learn the spatial transformations of the features\n",
    "        V_ij = self.spatial_transform(M_i)\n",
    "        ################ coordinate addition ################\n",
    "        #V_ij: SHAPE= [b, s0', s1', I, O, p0, p1], TYPE= tensor, VALUE= new vote matrix with values addition along an axis\n",
    "        if not len(self.spatial_dim): V_ij = self.coord_addition(V_ij)\n",
    "        ################ EM routing ################\n",
    "        # M_j: SHAPE=[b, s0', s1', O, p0, p0], TYPE= tensor, VALUE= pose matrix of the new capsules' layer\n",
    "        # a_j: SHAPE=[b, s0', s1', O], TYPE= tensor, VALUE= activations of the new capsules' layer\n",
    "        M_j, a_j = self.em_routing(V_ij, a_i)\n",
    "\n",
    "        if len(self.spatial_dim):\n",
    "            M_j = K.reshape(M_j, [-1, self.spatial_size[0], self.spatial_size[1], self.n_caps_out, self.pose_shape[0]*self.pose_shape[1]])\n",
    "            a_j = K.expand_dims(a_j, -1)\n",
    "            a_j = layers.Activation('sigmoid')(a_j)\n",
    "            net = layers.Concatenate()([M_j,a_j])\n",
    "        else:\n",
    "            net = layers.Activation('sigmoid')(a_j)\n",
    "        return net\n",
    "    def depthwise_conv(self, M_i, a_i):\n",
    "        def depthwise_operation (input, kernel, stride):\n",
    "            # (?, 14, 14, 32x(16)=512)\n",
    "            input_shape = input.get_shape()\n",
    "            size = input_shape[4]*input_shape[5] if len(input_shape)>5 else 1\n",
    "            input = tf.reshape(input, shape=[-1, input_shape[1], input_shape[2], input_shape[3]*size])\n",
    "            tile_filter = np.zeros(shape=[kernel, kernel, input_shape[3],\n",
    "                                          kernel * kernel], dtype=np.float32)\n",
    "            for i in range(kernel):\n",
    "                for j in range(kernel):\n",
    "                    tile_filter[i, j, :, i * kernel + j] = 1.0 # (3, 3, 512, 9)\n",
    "            # (3, 3, 512, 9)\n",
    "            tile_filter_op = tf.constant(tile_filter, dtype=tf.float32)\n",
    "            # (?, 6, 6, 4608)\n",
    "            output = tf.nn.depthwise_conv2d(input, tile_filter_op, strides=[\n",
    "                                            1, stride, stride, 1], padding='VALID')\n",
    "            output_shape = output.get_shape()\n",
    "            output = tf.reshape(output, shape=[-1, output_shape[1], output_shape[2], input_shape[3], kernel * kernel])\n",
    "            output = tf.transpose(output, perm=[0, 1, 2, 4, 3])\n",
    "            return output\n",
    "        # M_i: SHAPE=[b, s1, s2, I*p1*p2], TYPE= tensor, VALUE= prepare the tensor for a depthconv\n",
    "        M_i= K.reshape(M_i, shape=[self.batch_size, self.spatial_size_in[0], self.spatial_size_in[1], self.n_caps_in*self.pose_shape_in[0]*self.pose_shape_in[1]])\n",
    "        # M_i: SHAPE=[b, s1, s2, k1*k2, I*p1*p2], TYPE= tensor, VALUE= tiled pose matrix to be mutiplied by the transformation matrices to generate the votes\n",
    "        M_i = depthwise_operation(M_i, kernel=self.kernel_size[0], stride=self.strides)\n",
    "        # spatial_size: SHAPE=[1], TYPE= int, VALUE= new spatial size of the capsule (after the convolution)\n",
    "        self.spatial_size = [int(M_i.shape[1]), int(M_i.shape[2])]\n",
    "        # M_i: SHAPE=[b, s0', s1', k1*k2*I, p1, p2], TYPE= tensor, VALUE= reshape the pose matrix back to its standard shape\n",
    "        M_i= K.reshape(M_i, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in, self.pose_shape_in[0],self.pose_shape_in[1]])\n",
    "        # a_i: SHAPE=[b, s1', s2', k1*k2, I], TYPE= tensor, VALUE= tiled activations\n",
    "        a_i = depthwise_operation(a_i, kernel=self.kernel_size[0], stride=self.strides)\n",
    "        # a_i: SHAPE=[b, s1', s2', k1*k2*I], TYPE= tensor, VALUE= reshape the activation back to its standard shape\n",
    "        a_i= K.reshape(a_i, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in])\n",
    "        return M_i, a_i\n",
    "    def spatial_transform(self, M_i):\n",
    "        # M_i: SHAPE=[b, s0', s1', (k0*k1*)I, 1, p0, p1], TYPE= tensor, VALUE= expand the tensor with a value equal to the number output caps\n",
    "        M_i = K.expand_dims(M_i, -3)\n",
    "        # M_i: SHAPE=[b, s0', s1', (k0*k1*)I, O, p0, p1], TYPE= tensor, VALUE= expand the tensor with a value equal to the number output caps\n",
    "        M_i = K.tile(M_i, [1, 1, 1, 1, self.n_caps_out, 1, 1])\n",
    "\n",
    "        # W_ij: SHAPE=[b, s0', s1', (k0*k1*)I, O, p0, p1], VALUE= tiled transformation matrices, tile to batch_size\n",
    "        W_ij= K.tile(self.W_ij, [self.batch_size, self.spatial_size[0], self.spatial_size[1], 1, 1, 1, 1])\n",
    "\n",
    "        # V_ij: SHAPE=[b, s0', s1', (k0*k1*)I, O, p0, p1], TYPE= tensor, VALUE= vote matrices\n",
    "        V_ij = K.batch_dot(M_i, W_ij)\n",
    "        return V_ij\n",
    "    def coord_addition(self, V_ij):\n",
    "        \"\"\"\n",
    "        From the paper: \"We therefore share the transformation matrices between different positions of the same capsule type and\n",
    "        add the scaled coordinate (row, column) of the center of the receptive field of each capsule to the first\n",
    "        two elements of the right-hand column of its vote matrix.\"\n",
    "        \"\"\"\n",
    "        # V_ij: SHAPE=[b, s0', s1', k0*k1*I, O, p0*p1], TYPE= tensor, VALUE= adapt the shape for computation\n",
    "        V_ij = K.reshape(V_ij, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in, self.n_caps_out, self.pose_shape_in[0]*self.pose_shape_in[1]])\n",
    "        # H_values: SHAPE=[1, s0', 1, 1, 1], TYPE= tensor, VALUE= variational axis\n",
    "        H_values = K.reshape((tf.range(self.spatial_size[0], dtype=tf.float32) + 0.50) / self.spatial_size[0], [1, self.spatial_size[0], 1, 1, 1])\n",
    "        # H_values: SHAPE=[1, s0', 1, 1, 1], TYPE= tensor, VALUE= non variational axis\n",
    "        H_zeros = tf.constant(0.0, shape=[1, self.spatial_size[0], 1, 1, 1], dtype=tf.float32)\n",
    "        # H_values: SHAPE=[1, s0', 1, 1, p0*p1], TYPE= tensor, VALUE= new coordinates' offset\n",
    "        H_offset = tf.stack([H_values, H_zeros] + [H_zeros for _ in range(self.pose_shape_in[0]*self.pose_shape_in[1]-2)], axis=-1) \n",
    "        # W_values: SHAPE=[1, 1, s1', 1, 1, 1], TYPE= tensor, VALUE= variational axis\n",
    "        W_values = tf.reshape((tf.range(self.spatial_size[1], dtype=tf.float32) + 0.50) / self.spatial_size[1], [1, 1, self.spatial_size[1], 1, 1])\n",
    "        # H_values: SHAPE=[1, 1, s1', 1, 1], TYPE= tensor, VALUE= non variational axis\n",
    "        W_zeros = tf.constant(0.0, shape=[1, 1, self.spatial_size[1], 1, 1], dtype=tf.float32)\n",
    "        # H_values: SHAPE=[1, 1, s1', 1, p0*p1], TYPE= tensor, VALUE= new coordinates' offset\n",
    "        W_offset = tf.stack([W_zeros, W_values] + [W_zeros for _ in range(self.pose_shape_in[0]*self.pose_shape_in[1]-2)], axis=-1)\n",
    "        # V_ij: SHAPE=[b, s0', s1', I, O, p0*p1], TYPE= tensor, VALUE= V_ij in the new coordinates\n",
    "        V_ij = V_ij + H_offset + W_offset\n",
    "        # V_ij: SHAPE=[b, s0', s1', I, O, p0, p1], TYPE= tensor, VALUE= reshape back to the standard norm\n",
    "        V_ij = K.reshape(V_ij, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in, self.n_caps_out, self.pose_shape_in[0], self.pose_shape_in[1]])\n",
    "        return V_ij\n",
    "    def em_routing(self, V_ij, a_i):\n",
    "        def maximization(R_ij, V_ij, a_i, inv_temp):\n",
    "            # R_ij: SHAPE=[b, s0', s1', k0*k1*I, O, 1] or [b, s0'*s1'*I, O, 1], TYPE= tensor, VALUE=weights assignment according to the activation probabilities CAUTION!!!! maybe reshape it into k, k, A, B, 1 .... before multiplication\n",
    "            R_ij = R_ij * a_i\n",
    "            # R_ij: SHAPE=[b, (s0', s1',) 1, O, 1] , TYPE= tensor, VALUE=sum over all input capsules i\n",
    "            R_ij_sum = K.sum(R_ij, axis=-3, keepdims=True)\n",
    "            # M_j: SAHPE=[b, (s0', s1',) 1, O, p0*p1], TYPE= tensor, VALUE= mean of capsule j\n",
    "            M_j = K.sum(R_ij * V_ij, axis=-3, keepdims=True ) / R_ij_sum\n",
    "            # stdv_j: SAHPE=[b, (s0', s1',) 1, O, p0*p1], TYPE= tensor, VALUE= standard deviation of capsule j\n",
    "            stdv_j = K.sqrt(K.sum(R_ij_sum * tf.square(V_ij - M_j), axis=-3, keepdims=True) / R_ij_sum)\n",
    "            # cost_j_h: SHAPE=[b, (s0', s1',) 1, O, p0*p1], TYPE= tensor, VALUE= expected energy of a capsule j\n",
    "            cost_j_h = (self.beta_v + K.log(stdv_j + K.epsilon())) * R_ij_sum\n",
    "            # cost_j: SHAPE=[b, (s0', s1',) 1, O, 1], TYPE= tensor, VALUE= expected energy\n",
    "            cost_j = K.sum(cost_j_h, axis=-1, keepdims=True)\n",
    "            # cost_j_mean: SHAPE=[b, (s0', s1',) 1, 1, 1], TYPE= tensor, VALUE= mean the expected energy over the output capsules\n",
    "            cost_j_mean = K.mean(cost_j, axis=-2, keepdims=True)\n",
    "            # cost_j_stdv: SHAPE=[b, (s0', s1',) 1, 1, 1], TYPE= tensor, VALUE= mean the expected energy\n",
    "            cost_j_stdv = K.sqrt(K.sum(K.square(cost_j - cost_j_mean), axis=-2, keepdims=True) / self.n_caps_out)\n",
    "            # a_j_cost: SHAPE=[b, (s0', s1',) 1, O, 1], TYPE= tensor, VALUE= cost of the activation of capsule j\n",
    "            a_j_cost = self.beta_a + (cost_j_mean - cost_j) / (cost_j_stdv + K.epsilon())\n",
    "            # a_j: SHAPE=[b, (s0', s1',) 1, O, 1], TYPE= tensor, VALUE= activation of capsule j\n",
    "            a_j = tf.sigmoid(inv_temp * a_j_cost)\n",
    "            # a_j: SHAPE=[b, (s0', s1',) O], TYPE= tensor, VALUE= squeezed activation of capsule j\n",
    "            a_j = K.squeeze(K.squeeze(a_j, axis=-3), axis=-1)\n",
    "            # M_j: SAHPE=[b, (s0', s1',) O, p0*p1], TYPE= tensor, VALUE=squeezed mean of capsule j (pose matrix)\n",
    "            M_j = K.squeeze(M_j, axis=-3)\n",
    "            # stdv_j: SAHPE=[b, (s0', s1',) O, p0*p1], TYPE= tensor, VALUE=squeezed standard deviation of capsule j\n",
    "            stdv_j = K.squeeze(stdv_j, axis=-3)\n",
    "            return M_j, stdv_j, a_j\n",
    "        def estimation(M_j, stdv_j, V_ij, a_j):\n",
    "            # M_j: SAHPE=[b, (s0', s1',) 1, O, p0*p1], TYPE= tensor, VALUE=squeezed mean of capsule j (pose matrix)\n",
    "            M_j = K.expand_dims(M_j, -3)     \n",
    "            # a_j: SAHPE=[b, (s0', s1',) 1, O, 1], TYPE= tensor, VALUE=squeezed mean of capsule j (pose matrix)\n",
    "            a_j = K.expand_dims(K.expand_dims(a_j, -2), -1)\n",
    "            # stdv_j: SAHPE=[b, (s0', s1',) 1, O, p0*p1], TYPE= tensor, VALUE=squeezed mean of capsule j (pose matrix)\n",
    "            stdv_j = K.expand_dims(stdv_j, -3)\n",
    "            # R_ij: SHAPE= [b, s0', s1', k0*k1*I, O, 1] or [b, s0'*s1'*I, O, 1], TYPE= tensor, VALUE= routing matrix\n",
    "            a_j_p_j  = K.log(a_j + K.epsilon()) - K.sum(K.square(V_ij - M_j) /(2 * tf.square(stdv_j)), axis=-1, keepdims=True) - K.sum(tf.log(stdv_j + K.epsilon()), axis=-1, keepdims=True)\n",
    "            # R_ij: SHAPE= [b, s0', s1', k0*k1*I, O, 1], TYPE= tensor, VALUE= activated routing matrix\n",
    "            R_ij = tf.nn.softmax(a_j_p_j, dim=len(a_j_p_j.get_shape().as_list())-2)\n",
    "            return R_ij\n",
    "        if len(self.spatial_dim):\n",
    "            # V_ij: SHAPE=[b, s0', s1', k0*k1*I, O, p0*p1], TYPE= tensor, VALUE= adapt the shape for computation\n",
    "            V_ij = K.reshape(V_ij, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.kernel_size[0]*self.kernel_size[1]*self.n_caps_in, self.n_caps_out, self.pose_shape[0]*self.pose_shape[1]])\n",
    "            # ai: SHAPE=[b, s0', s1', k0*k1*I, 1, 1], TYPE= tensor, VALUE= expanded i activations\n",
    "            a_i = K.expand_dims(K.expand_dims(a_i,-1),-1)\n",
    "            # R_ij: SHAPE=[k0*k1*I, O, 1], TYPE= tensor, VALUE= routing assignment matrix from each input capsule (i) in L to each output capsule (j) in L+1 initilized with uniform distribution\n",
    "            R_ij = K.constant(1.0/self.n_caps_out, shape=(self.kernel_size[0]*self.kernel_size[0]*self.n_caps_in, self.n_caps_out, 1))\n",
    "        else:\n",
    "            # V_ij: SHAPE=[b, s0'*s1'*I, O, p0*p1], TYPE= tensor, VALUE= adapt the shape for computation\n",
    "            V_ij = K.reshape(V_ij, shape=[self.batch_size, self.spatial_size[0]*self.spatial_size[1]*self.n_caps_in, self.n_caps_out, self.pose_shape[0]*self.pose_shape[1]])\n",
    "            # a_i: SHAPE=[b, s0'*s1'*I, 1, 1], TYPE= tensor, VALUE= reshape to standard form\n",
    "            a_i = K.reshape(a_i, shape=[self.batch_size, self.spatial_size[0]*self.spatial_size[1]*self.n_caps_in, 1, 1])\n",
    "            # R_ij: SHAPE=[s0'*s1'*I, O, 1], TYPE= tensor, VALUE= routing assignment matrix from each input capsule (i) in L to each output capsule (j) in L+1 initilized with uniform distribution\n",
    "            R_ij = K.constant(1.0/self.n_caps_out, shape=(self.spatial_size[0]*self.spatial_size[0]*self.n_caps_in, self.n_caps_out, 1))\n",
    "        for iter in range(self.routing_iters):\n",
    "            # inv_temp: SHAPE=[1], TYPE= int, VALUE= Lambda: inverse temperature schedule (1, min(routing_iters, 3.0)-1)\n",
    "            inv_temp = 1.0 + (min(self.routing_iters, 3.0) - 1.0) * iter / max(1.0, self.routing_iters - 1.0)\n",
    "            # M_j: SAHPE=[b, (s0', s1',) O, p0*p1], TYPE= tensor, VALUE= mean of capsule j\n",
    "            # stdv_j: SAHPE=[b, (s0', s1',) O, p0*p1], TYPE= tensor, VALUE= standard deviation of capsule j\n",
    "            # a_j: SHAPE= [b, (s0', s1',) O], TYPE= tensor, VALUE= activation of capsule j\n",
    "            M_j, stdv_j, a_j = maximization(R_ij, V_ij, a_i, inv_temp=inv_temp)\n",
    "            # R_ij: SHAPE= [b, (s0', s1',) k0*k1*I, O, 1], TYPE= tensor, VALUE= activated routing matrix\n",
    "            if iter < self.routing_iters - 1:\n",
    "                R_ij = estimation(M_j, stdv_j, V_ij, a_j)\n",
    "        # M_j: SHAPE=[b, (s0', s1',) O, p0, p1], TYPE= tensor, VALUE= reshape back to the standard norm\n",
    "        M_j = K.reshape(M_j, shape=[self.batch_size, self.spatial_size[0], self.spatial_size[1], self.n_caps_out, self.pose_shape[0], self.pose_shape[1]])\n",
    "        return M_j, a_j\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if len(self.spatial_dim):\n",
    "            # M_j: SHAPE=[b, (s0', s1',) O, p0, p1], TYPE= tensor, VALUE= pose matrix of the new capsules' layer (reshaped back to p0xp1 pose matrix)\n",
    "            output_sh=[input_shape[0], self.spatial_size[0], self.spatial_size[1], self.n_caps_out, self.pose_shape[0]*self.pose_shape[1]+1]\n",
    "        else: \n",
    "            output_sh=[input_shape[0], self.n_caps_out]\n",
    "        return tuple(output_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCapsNet(Discriminator):\n",
    "    def __init__ (self, batch_size, name='MCapsNet', **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        super(MCapsNet, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "    def build_sequential(self, input_shape, output_shape, L1_n, L2_n, L3_n, L4_n, pose_shape=[4,4], routing=3, decoder=False): #L3_n is the same as output_shape     \n",
    "        self.output_shape = output_shape\n",
    "        # inputs = img_shape : Input\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # net = [b, s0, s1, A] : ReLU Conv1\n",
    "        net = layers.Conv2D(filters=L1_n, kernel_size=[5,5], strides=2, padding='SAME', activation='relu', name='ReLU_Conv1')(inputs) # add batch normalization ?? \n",
    "        # net = [ poses = [?, s0, s1, B, p*p], activations = [?, s0, s1, B] ] : PrimaryCaps\n",
    "        net = self.PrimaryCaps(net, pose_shape=pose_shape, n_caps_out=L2_n, kernel_size=[1,1], strides=1, padding='VALID', name='PrimaryCaps')\n",
    "        # nets = [ poses = [?, s0', s1', C, p*p], activations = [?, s0', s1', C] ] : ConvCaps1\n",
    "        net = CapsLayer(n_caps_out=L3_n, pose_shape=pose_shape,  kernel_size=[3,3], strides=2,routing_iters=routing, name='ConvCaps1')(net)\n",
    "        # nets = [ poses (?, s0'', s1'', D, p*p), activations = [?, s0'', s1'', D] ] : ConvCaps2\n",
    "        net = CapsLayer(n_caps_out=L4_n, pose_shape=pose_shape,  kernel_size=[3,3], strides=1,routing_iters=routing, name='ConvCaps2')(net)\n",
    "        # output  = [ poses = [?, E, p*p], activations = [?, E] ] : Class Capsules\n",
    "        net = CapsLayer(n_caps_out=np.prod(output_shape), pose_shape=pose_shape, routing_iters=routing, name='Class_Capsules')(net)\n",
    "        return models.Model(inputs, net)\n",
    "    \n",
    "    def PrimaryCaps(self,inputs, pose_shape, n_caps_out, kernel_size, strides, padding, name):\n",
    "        #M = [b, s0, s1, I*p0*p1] : generate the pose matrices of the caps\n",
    "        M = layers.Conv2D(filters=n_caps_out*pose_shape[0]*pose_shape[1], kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "        #M = [b, s0, s1, I, p0, p1] : reshape the pose matrices from 16 scalar values into a 4x4 matrix\n",
    "        M = layers.Reshape(target_shape=[M.get_shape().as_list()[1], M.get_shape().as_list()[2], n_caps_out, pose_shape[0]*pose_shape[1]])(M)\n",
    "        #a = [b, s0, s1, I] : generate the activation for the caps\n",
    "        a = layers.Conv2D(filters=n_caps_out, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "        a = layers.Activation('sigmoid')(a)\n",
    "        a = layers.Reshape(target_shape=[inputs.get_shape().as_list()[1], inputs.get_shape().as_list()[2], n_caps_out, 1])(a)\n",
    "        net = layers.Concatenate()([M,a])\n",
    "        return net\n",
    "    \n",
    "    def compile(self, batch_size, n_samples, optimizer=None, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        iterations_per_epoch = int(n_samples / batch_size)\n",
    "        self.margin = tf.train.piecewise_constant(tf.Variable(1, trainable=False, dtype=tf.int32),\n",
    "                                                 boundaries=[ int(iterations_per_epoch * 10.0 * x /7) for x in range(1, 8)], \n",
    "                                                 values=[x / 10.0 for x in range(2, 10)])\n",
    "        if optimizer is None: optimizer = self.loss_fn\n",
    "        super(MCapsNet, self).compile(optimizer=optimizer, **kwargs)\n",
    "        \n",
    "    def fit(self, x, y, batch_size, **kwargs):\n",
    "        super(MCapsNet, self).fit(x=x, y=y, batch_size=batch_size, **kwargs)\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred):\n",
    "        # y_pred_t = [b, 1] : true predictions\n",
    "        y_pred_true = K.reshape(tf.boolean_mask(y_pred,tf.equal(y_true, 1)), shape=(self.batch_size, 1))\n",
    "        # y_pred_i = [b, 9] : false predictions\n",
    "        y_pred_false = K.reshape(tf.boolean_mask(y_pred,tf.equal(y_true, 0)), shape=(self.batch_size, np.prod(self.output_shape)-1))\n",
    "        # loss = [1] : loss function\n",
    "        #loss = K.sum(K.square(K.relu(self.margin - (y_pred_true - y_pred_false))))\n",
    "        loss = K.sum(K.square(K.maximum(0., self.margin - (y_pred_true - y_pred_false))))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation (incl. Inception score and Fréchet Inception Distance) engines of GAN.\n",
    "fit_generator function has a similar strcture as a keras training engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, name='GAN', **kwargs):\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.G = None\n",
    "        self.D = None\n",
    "        \n",
    "    def build_compile(self):\n",
    "        pass\n",
    "    \n",
    "    def split_kwargs(self, **kwargs):\n",
    "        kwargs_gen = {};\n",
    "        kwargs_disc = {};\n",
    "        for key, value in kwargs.items():\n",
    "            if 'G' in value.keys():\n",
    "                kwargs_gen[key]=value['G']\n",
    "            if 'D' in value.keys():\n",
    "                kwargs_disc[key]=value['D']\n",
    "        return kwargs_gen, kwargs_disc \n",
    "        \n",
    "    def write_log(self,callback, names, logs, batch_no):\n",
    "        for name, value in zip(names, logs):\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value\n",
    "            summary_value.tag = name\n",
    "            callback.writer.add_summary(summary, batch_no)\n",
    "            callback.writer.flush()\n",
    "            \n",
    "    def get_eval_scores(self, splits=10, n_samples=None):\n",
    "        def preprocessing(imgs):\n",
    "            if (len(np.shape(imgs))==3 or np.shape(imgs)[-1]==1):\n",
    "                imgs = np.squeeze(imgs)\n",
    "                imgs = np.stack((imgs,)*3, -1)\n",
    "                imgs = np.rollaxis(imgs, 3, -1)\n",
    "            return imgs\n",
    "        \n",
    "        def inception_logits(images, num_splits=1):\n",
    "            #images=tf.transpose(images,[0,2,3,1])\n",
    "            size = 299\n",
    "            images = tf.image.resize_bilinear(images, [size, size])\n",
    "            generated_images_list = array_ops.split(\n",
    "            images, num_or_size_splits=num_splits)\n",
    "            logits = functional_ops.map_fn(\n",
    "                fn=functools.partial(tf.contrib.gan.eval.run_inception, output_tensor='logits:0'),\n",
    "                elems=array_ops.stack(generated_images_list),\n",
    "                parallel_iterations=1,\n",
    "                back_prop=False,\n",
    "                swap_memory=True,\n",
    "                name='RunClassifier')\n",
    "            logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
    "            return logits\n",
    "        if n_samples is None:\n",
    "            n_samples = self.n_samples\n",
    "        G_z = self.G.model.predict(np.random.normal(0, 1, (n_samples,)+self.G.input_shape))\n",
    "        x = self.imgs[:n_samples]\n",
    "        imgs_g = preprocessing(G_z)\n",
    "        imgs_x = preprocessing(x)\n",
    "        BATCH_SIZE= 100\n",
    "        session = tf.InteractiveSession()\n",
    "        # Run images through Inception.\n",
    "        inception_images_x=tf.placeholder(tf.float32,[BATCH_SIZE,None,None, 3])\n",
    "        # Run images through Inception.\n",
    "        inception_images_g=tf.placeholder(tf.float32,[BATCH_SIZE,None,None, 3])\n",
    "        \n",
    "        logits_x=inception_logits(inception_images_x)\n",
    "        logits_g=inception_logits(inception_images_g)\n",
    "\n",
    "        def get_inception_probs(inps, inception_imgs, logits):\n",
    "            preds = []\n",
    "            n_batches = len(inps)//BATCH_SIZE\n",
    "            for i in range(n_batches):\n",
    "                inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "                pred = logits.eval({inception_imgs:inp})[:,:1000]\n",
    "                preds.append(pred)\n",
    "                \n",
    "            preds = np.concatenate(preds, 0)\n",
    "            preds=np.exp(preds)/np.sum(np.exp(preds),1,keepdims=True)\n",
    "            return preds\n",
    "\n",
    "        def preds2IS(preds_g, splits):\n",
    "            scores = []\n",
    "            for i in range(splits):\n",
    "                part = preds_g[(i * preds_g.shape[0] // splits):((i + 1) * preds_g.shape[0] // splits), :]\n",
    "                kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "                kl = np.mean(np.sum(kl, 1))\n",
    "                scores.append(np.exp(kl))\n",
    "            return np.mean(scores), np.std(scores)\n",
    "        \n",
    "        def pred2FID(real_images, generated_images, batch_size,\n",
    "                                   num_inception_images):\n",
    "            size = 299\n",
    "            resized_real_images = tf.image.resize_bilinear(real_images, [size, size])\n",
    "            resized_generated_images = tf.image.resize_bilinear(\n",
    "              generated_images, [size, size])\n",
    "\n",
    "            # Compute Frechet Inception Distance.\n",
    "            num_batches = batch_size // num_inception_images\n",
    "            tfgan = tf.contrib.gan\n",
    "            fid = tfgan.eval.frechet_inception_distance(\n",
    "              resized_real_images, resized_generated_images, num_batches=num_batches)\n",
    "            sess = tf.Session()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(fid)\n",
    "            \n",
    "        def get_score(splits):\n",
    "            preds_g = get_inception_probs(imgs_g, inception_images_g, logits_g)\n",
    "            preds_x = get_inception_probs(imgs_x, inception_images_x, logits_x)\n",
    "            mean,std = preds2IS(preds_g,splits)\n",
    "            fid = pred2FID(imgs_x, imgs_g, BATCH_SIZE, splits)\n",
    "            return mean,std, fid  # Reference values: 11.34 for 49984 CIFAR-10 training set images, or mean=11.31, std=0.08 if in 10 splits (default).\n",
    "        score = get_score(splits)\n",
    "        tf.InteractiveSession.close(session)\n",
    "        return score\n",
    "    \n",
    "    def plot_generated_samples(self, imgs, grid=[10,10], imgsize=[10,10], img_range=[0,255], cmap='gray', logdir=None, img_name=None):\n",
    "        fig= plt.figure(figsize=(imgsize[0], imgsize[1]))\n",
    "        if True:\n",
    "            # Get random samples\n",
    "            imgs= imgs[0:grid[0]*grid[1]]\n",
    "            if cmap is 'gray': imgs = np.squeeze(imgs, -1)\n",
    "            if np.shape(imgs)[0] is 1: imgs = np.squeeze(imgs, 0)\n",
    "            imgs = ((imgs-img_range[0])*255/(img_range[1]-img_range[0])).astype(np.uint8)\n",
    "            # Create a figure object\n",
    "\n",
    "            # Show images\n",
    "            for i in range(0, grid[0]*grid[1]):        \n",
    "                fig.add_subplot(grid[0], grid[1], i+1)\n",
    "                img = imgs[i]\n",
    "                plt.imshow(img, cmap=cmap)\n",
    "                plt.axis('off')\n",
    "        \n",
    "        #plt.show()\n",
    "        if logdir and img_name:\n",
    "            if not os.path.exists(os.path.join(logdir, 'generated_images')): os.makedirs(os.path.join(logdir, 'generated_images'))\n",
    "            fig.savefig(os.path.join(logdir, os.path.join('generated_images', img_name+'.svg')))\n",
    "            \n",
    "    def train_generator_gan(self, x, batch_size, noise_shape, shift_fraction=0.):\n",
    "        Y_trash = np.ones(x.shape[0])\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, Y_trash, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, _ = generator.next()\n",
    "            ones = np.ones((np.shape(x_batch)[0], 1))\n",
    "            zeros = np.zeros((np.shape(x_batch)[0], 1))\n",
    "            noise = np.random.normal(0, 1, (np.shape(x_batch)[0],)+noise_shape)\n",
    "            G_noise = self.G.model.predict(np.random.normal(0, 1, (np.shape(x_batch)[0],)+noise_shape))\n",
    "            yield ({'G': noise, 'D': [x_batch, G_noise]}, {'G': np.append(ones, zeros, axis=-1), 'D': [np.append(ones, zeros, axis=-1), np.append(zeros, ones, axis=-1)]})\n",
    "\n",
    "    def test_generator_gan(self, x, noise_shape):\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        zeros = np.zeros((x.shape[0], 1))\n",
    "        noise = np.random.normal(0, 1, (x.shape[0],)+ noise_shape)\n",
    "        G_noise = self.G.model.predict(np.random.normal(0, 1, (x.shape[0],)+ noise_shape))\n",
    "        return ({'G': noise, 'D': [x, G_noise]}, {'G': np.append(ones, zeros, axis=-1), 'D': [np.append(ones, zeros, axis=-1), np.append(zeros, ones, axis=-1)]})\n",
    "    \n",
    "    def fit(self, x, batch_size, epochs, disc_iters=1, gen_iters=1, callbacks=[],  grid=[10,10], imgsize=[10,10], img_range=[-1, 1], y=None, eval_scores=None, load_weights={'G':None, 'D':None}, validation_data=None,\n",
    "            PlotGenetaredSamples=True, PlotModel = True, TensorBoard=True, debug=False, ModelCheckpoint= True, CSVLogger=True, logdir='./', fixed_latent=False, checkpoint_interval=None,  **kwargs):\n",
    "        self.imgs = x\n",
    "        cb = []\n",
    "        cb += callbacks\n",
    "        self.grid = grid\n",
    "        self.eval_scores = eval_scores\n",
    "        self.disc_iters = disc_iters\n",
    "        self.gen_iters = gen_iters\n",
    "        self.n_samples = x.shape[0]\n",
    "        self.batch_size= batch_size\n",
    "        self.target_scale = img_range\n",
    "        self.imgsize = imgsize\n",
    "        self.logdir = logdir\n",
    "        self.PlotGenetaredSamples = PlotGenetaredSamples\n",
    "        self.fixed_latent = fixed_latent\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        if CSVLogger: cb.append(cbks.CSVLogger(os.path.join(logdir, 'history.csv')))\n",
    "        if TensorBoard: cb.append(cbks.TensorBoard(log_dir=os.path.join(logdir, 'tb'),\n",
    "                                   batch_size=self.batch_size, histogram_freq=debug))\n",
    "        \n",
    "        if PlotModel:\n",
    "            plot_model(self.G.sequential, to_file=os.path.join(logdir, 'gen_'+self.G.name+'.svg'), show_shapes=True)\n",
    "            plot_model(self.D.sequential, to_file=os.path.join(logdir, 'disc_'+self.D.name+'.svg'), show_shapes=True)\n",
    "            plot_model(self.model, to_file=os.path.join(logdir, self.name+'.svg'), show_shapes=True)\n",
    "        if load_weights['G'] : \n",
    "            print(\"loading generator's weights - start\")\n",
    "            self.G.model.load_weights(load_weights['G'])\n",
    "            print(\"loading generator's weights - end\")\n",
    "        if load_weights['D'] :\n",
    "            print(\"loading discriminator's weights - start\")\n",
    "            self.D.model.load_weights(load_weights['D'])\n",
    "            print(\"loading discriminator's weights - end\")\n",
    "        self.fit_generator(generator=self.train_generator_gan(x, batch_size, self.G.input_shape, 0.1),\n",
    "                           steps_per_epoch=int(x.shape[0] / batch_size),\n",
    "                           epochs=epochs,\n",
    "                           validation_data=self.test_generator_gan(x, self.G.input_shape),\n",
    "                           callbacks= cb, ModelCheckpoint= ModelCheckpoint, logdir=logdir,\n",
    "                           **kwargs)\n",
    "    def fit_generator(self,generator,\n",
    "                      steps_per_epoch=None,\n",
    "                      epochs=1,\n",
    "                      verbose=1,\n",
    "                      callbacks=None,\n",
    "                      ModelCheckpoint=None,\n",
    "                      validation_data=None,\n",
    "                      validation_steps=None,\n",
    "                      class_weight=None,\n",
    "                      logdir='./',\n",
    "                      max_queue_size=10,\n",
    "                      workers=1,\n",
    "                      use_multiprocessing=False,\n",
    "                      shuffle=True,\n",
    "                      initial_epoch=0):\n",
    "        \n",
    "        \n",
    "        \"\"\"See docstring for `Model.fit_generator`.\"\"\"\n",
    "        wait_time = 0.01  # in seconds\n",
    "        epoch = initial_epoch\n",
    "\n",
    "        do_validation = bool(validation_data)\n",
    "        gan_validation_data = [x['G'] for x in validation_data]\n",
    "        disc_validation_data = [x['D'] for x in validation_data]\n",
    "        self.model._make_train_function()\n",
    "        self.D.model._make_train_function()\n",
    "        if do_validation:\n",
    "            self.model._make_test_function()\n",
    "            self.D.model._make_test_function()\n",
    "\n",
    "        is_sequence = isinstance(generator, utils.data_utils.Sequence)\n",
    "        if not is_sequence and use_multiprocessing and workers > 1:\n",
    "            warnings.warn(\n",
    "                UserWarning('Using a generator with `use_multiprocessing=True`'\n",
    "                            ' and multiple workers may duplicate your data.'\n",
    "                            ' Please consider using the`keras.utils.Sequence'\n",
    "                            ' class.'))\n",
    "        if steps_per_epoch is None:\n",
    "            if is_sequence:\n",
    "                steps_per_epoch = len(generator)\n",
    "            else:\n",
    "                raise ValueError('`steps_per_epoch=None` is only valid for a'\n",
    "                                 ' generator based on the '\n",
    "                                 '`keras.utils.Sequence`'\n",
    "                                 ' class. Please specify `steps_per_epoch` '\n",
    "                                 'or use the `keras.utils.Sequence` class.')\n",
    "\n",
    "        # python 2 has 'next', 3 has '__next__'\n",
    "        # avoid any explicit version checks\n",
    "        gan_val_gen = (hasattr(gan_validation_data, 'next') or\n",
    "                   hasattr(gan_validation_data, '__next__') or\n",
    "                   isinstance(gan_validation_data, utils.data_utils.Sequence))\n",
    "        disc_val_gen = (hasattr(disc_validation_data, 'next') or\n",
    "                   hasattr(disc_validation_data, '__next__') or\n",
    "                   isinstance(disc_validation_data, utils.data_utils.Sequence))\n",
    "        if (gan_val_gen and not isinstance(gan_validation_data, utils.data_utils.Sequence) and\n",
    "                not validation_steps) or (disc_val_gen and not isinstance(disc_validation_data, utils.data_utils.Sequence) and\n",
    "                not validation_steps):\n",
    "            raise ValueError('`validation_steps=None` is only valid for a'\n",
    "                             ' generator based on the `keras.utils.Sequence`'\n",
    "                             ' class. Please specify `validation_steps` or use'\n",
    "                             ' the `keras.utils.Sequence` class.')\n",
    "        \n",
    "        # Prepare display labels.\n",
    "        for i in range(len(self.model.metrics_names)):\n",
    "            self.model.metrics_names[i] = 'cb'+str(i)+'_'+ self.model.metrics_names[i]\n",
    "        for i in range(len(self.D.model.metrics_names)):\n",
    "            self.D.model.metrics_names[i] = 'cb'+str(i)+'_'+ self.D.model.metrics_names[i]\n",
    "        out_labels = ['gen_'+x for x in self.model.metrics_names] + ['disc_'+x for x in self.D.model.metrics_names]\n",
    "                \n",
    "        callback_metrics = out_labels + ['val_' + n for n in out_labels]\n",
    "        \n",
    "        if self.eval_scores:\n",
    "            callback_metrics += ['IS_mean', 'IS_stdv', 'FID']\n",
    "        # prepare callbacks\n",
    "        self.model.history = cbks.History()\n",
    "        self.D.model.history = cbks.History()\n",
    "        _callbacks = [cbks.BaseLogger(\n",
    "            stateful_metrics= ['gen_'+x for x in self.model.metrics_names] + ['disc_'+x for x in self.D.model.metrics_names])]\n",
    "        if verbose:\n",
    "            _callbacks.append(\n",
    "                cbks.ProgbarLogger(\n",
    "                    count_mode='steps',\n",
    "                    stateful_metrics=['gen_'+x for x in self.model.metrics_names] + ['disc_'+x for x in self.D.model.metrics_names]))\n",
    "        _callbacks += (callbacks or []) + [self.model.history] + [self.D.model.history] \n",
    "        _callbacks = cbks.CallbackList(_callbacks)\n",
    "\n",
    "        # it's possible to callback a different model than self:\n",
    "        if hasattr(self.model, 'callback_model') and self.model.callback_model:\n",
    "            gan_callback_model = self.model.callback_model\n",
    "        else:\n",
    "            gan_callback_model = self.model\n",
    "        if hasattr(self.D.model, 'callback_model') and self.D.model.callback_model:\n",
    "            disc_callback_model = self.D.model.callback_model\n",
    "        else:\n",
    "            disc_callback_model = self.D.model\n",
    "        _callbacks.set_model(gan_callback_model)\n",
    "        \n",
    "        _callbacks.set_params({\n",
    "            'epochs': epochs,\n",
    "            'steps': steps_per_epoch,\n",
    "            'verbose': verbose,\n",
    "            'do_validation': do_validation,\n",
    "            'metrics': callback_metrics,\n",
    "        })\n",
    "        _callbacks.on_train_begin()\n",
    "        gan_enqueuer = None\n",
    "        disc_enqueuer = None\n",
    "        gan_val_enqueuer = None\n",
    "        disc_val_enqueuer = None\n",
    "\n",
    "        try:\n",
    "            if do_validation:\n",
    "                if gan_val_gen and disc_val_gen and workers > 0:\n",
    "                    gen_val_data = gan_validation_data\n",
    "                    disc_val_data = disc_validation_data\n",
    "                    # Create an Enqueuer that can be reused\n",
    "                    if isinstance(gan_val_data, utils.data_utils.Sequence):\n",
    "                        gan_val_enqueuer = OrderedEnqueuer(gan_val_data,\n",
    "                                                       use_multiprocessing=use_multiprocessing)\n",
    "                        gan_validation_steps = len(gan_val_data)\n",
    "                    else:\n",
    "                        gan_val_enqueuer = utils.data_utils.GeneratorEnqueuer(gan_val_data,\n",
    "                                                         use_multiprocessing=use_multiprocessing)\n",
    "                    if isinstance(disc_val_data, utils.data_utils.Sequence):\n",
    "                        disc_val_enqueuer = OrderedEnqueuer(disc_val_data,\n",
    "                                                       use_multiprocessing=use_multiprocessing)\n",
    "                        disc_validation_steps = len(disc_val_data)\n",
    "                    else:\n",
    "                        disc_val_enqueuer = utils.data_utils.GeneratorEnqueuer(disc_val_data,\n",
    "                                                         use_multiprocessing=use_multiprocessing)\n",
    "                    gan_val_enqueuer.start(workers=workers,\n",
    "                                       max_queue_size=max_queue_size)\n",
    "                    gan_val_enqueuer_gen = gan_val_enqueuer.get()\n",
    "                    disc_val_enqueuer.start(workers=workers,\n",
    "                                       max_queue_size=max_queue_size)\n",
    "                    disc_val_enqueuer_gen = disc_val_enqueuer.get()\n",
    "                elif gan_val_gen or disc_val_gen:\n",
    "                    if (gan_val_gen):\n",
    "                        gan_val_data = gan_validation_data\n",
    "                        if isinstance(gan_val_data, utils.data_utils.Sequence):\n",
    "                            gan_val_enqueuer_gen = iter(gan_val_data)\n",
    "                        else:\n",
    "                            gan_val_enqueuer_gen = gan_val_data\n",
    "                    if (disc_val_gen):\n",
    "                        disc_val_data = disc_validation_data\n",
    "                        if isinstance(disc_val_data, utils.data_utils.Sequence):\n",
    "                            disc_val_enqueuer_gen = iter(disc_val_data)\n",
    "                        else:\n",
    "                            disc_val_enqueuer_gen = disc_val_data\n",
    "                else:\n",
    "                    # Prepare data for validation\n",
    "                    if len(gan_validation_data) == 2 or len(disc_validation_data) == 2:\n",
    "                        if len(gan_validation_data) == 2:\n",
    "                            gan_val_x, gan_val_y = gan_validation_data\n",
    "                            gan_val_sample_weight = None\n",
    "                        if len(disc_validation_data) == 2:\n",
    "                            disc_val_x, disc_val_y = disc_validation_data\n",
    "                            disc_val_sample_weight = None\n",
    "                    elif len(gan_validation_data) == 3 or len(disc_validation_data) == 3:\n",
    "                        if len(gan_validation_data) == 3:\n",
    "                            gan_val_x, gen_val_y, gan_val_sample_weight = gan_validation_data\n",
    "                        if len(disc_validation_data) == 3:\n",
    "                            disc_val_x, disc_val_y, disc_val_sample_weight = disc_validation_data\n",
    "                        \n",
    "                    else:\n",
    "                        raise ValueError('`validation_data` should be a tuple '\n",
    "                                         '`(val_x, val_y, val_sample_weight)` '\n",
    "                                         'or `(val_x, val_y)`. Found: ' +\n",
    "                                         str(gan_validation_data) + str(disc_validation_data))\n",
    "                    gan_val_x, gan_val_y, gan_val_sample_weights = self.model._standardize_user_data(\n",
    "                        gan_val_x, gan_val_y, gan_val_sample_weight)\n",
    "                    disc_val_x, disc_val_y, disc_val_sample_weights = self.D.model._standardize_user_data(\n",
    "                        disc_val_x , disc_val_y,\n",
    "                        disc_val_sample_weight)\n",
    "                    gan_val_data = gan_val_x + gan_val_y + gan_val_sample_weights\n",
    "                    disc_val_data = disc_val_x + disc_val_y + disc_val_sample_weights\n",
    "                    if self.model.uses_learning_phase and not isinstance(K.learning_phase(),\n",
    "                                                                    int):\n",
    "                        gan_val_data += [0.]\n",
    "                    if self.D.model.uses_learning_phase and not isinstance(K.learning_phase(),\n",
    "                                                                    int):\n",
    "                        disc_val_data += [0.]\n",
    "                    for cbk in _callbacks:\n",
    "                        cbk.validation_data = gan_val_data\n",
    "                        cbk.validation_data = disc_val_data\n",
    "\n",
    "            if workers > 0:\n",
    "                if is_sequence:\n",
    "                    enqueuer = OrderedEnqueuer(\n",
    "                        generator,\n",
    "                        use_multiprocessing=use_multiprocessing,\n",
    "                        shuffle=shuffle)\n",
    "                else:\n",
    "                    enqueuer = utils.data_utils.GeneratorEnqueuer(\n",
    "                        generator,\n",
    "                        use_multiprocessing=use_multiprocessing,\n",
    "                        wait_time=wait_time)\n",
    "                enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n",
    "                output_generator = enqueuer.get()\n",
    "            else:\n",
    "                if is_sequence:\n",
    "                    output_generator = iter(generator)\n",
    "                else:\n",
    "                    output_generator = generator\n",
    "            gan_callback_model.stop_training = False\n",
    "            disc_callback_model.stop_training = False\n",
    "                      \n",
    "            def generator_next():\n",
    "                generator_output = next(output_generator)\n",
    "                gan_generator_output = [x['G'] for x in generator_output]\n",
    "                disc_generator_output = [x['D'] for x in generator_output]\n",
    "                if not hasattr(gan_generator_output, '__len__'):\n",
    "                    raise ValueError('Output of generator should be '\n",
    "                                     'a tuple `(x, y, sample_weight)` '\n",
    "                                     'or `(x, y)`. Found: ' +\n",
    "                                     str(gan_generator_output))\n",
    "                if not hasattr(disc_generator_output, '__len__'):\n",
    "                    raise ValueError('Output of generator should be '\n",
    "                                     'a tuple `(x, y, sample_weight)` '\n",
    "                                     'or `(x, y)`. Found: ' +\n",
    "                                     str(disc_generator_output))\n",
    "\n",
    "                if len(gan_generator_output) == 2:\n",
    "                    gan_x, gan_y = gan_generator_output\n",
    "                    gan_sample_weight = None\n",
    "                elif len(gan_generator_output) == 3:\n",
    "                    gan_x, gan_y, gan_sample_weight = gan_generator_output\n",
    "                else:\n",
    "                    raise ValueError('Output of generator should be '\n",
    "                                     'a tuple `(x, y, sample_weight)` '\n",
    "                                     'or `(x, y)`. Found: ' +\n",
    "                                     str(gan_generator_output))\n",
    "                if len(disc_generator_output) == 2:\n",
    "                    disc_x, disc_y = disc_generator_output\n",
    "                    disc_sample_weight = None\n",
    "                elif len(disc_generator_output) == 3:\n",
    "                    disc_x, disc_y, disc_sample_weight = disc_generator_output\n",
    "                else:\n",
    "                    raise ValueError('Output of generator should be '\n",
    "                                     'a tuple `(x, y, sample_weight)` '\n",
    "                                     'or `(x, y)`. Found: ' +\n",
    "                                     str(disc_generator_output))\n",
    "                return gan_x, gan_y, gan_sample_weight, disc_x, disc_y, disc_sample_weight\n",
    "            # Construct epoch logs.\n",
    "            epoch_logs = {}\n",
    "            if self.fixed_latent:\n",
    "                noise= np.random.normal(0, 1, (self.grid[0]*self.grid[1],100))\n",
    "            \n",
    "            while epoch < epochs:\n",
    "                for m in self.model.stateful_metric_functions:\n",
    "                    m.reset_states()\n",
    "                for m in self.D.model.stateful_metric_functions:\n",
    "                    m.reset_states()\n",
    "                _callbacks.on_epoch_begin(epoch)\n",
    "                steps_done = 0\n",
    "                batch_index = 0\n",
    "                while steps_done < steps_per_epoch:\n",
    "                    gan_x, gan_y, gan_sample_weight, disc_x, disc_y, disc_sample_weight = generator_next()\n",
    "                    # build batch logs\n",
    "                    batch_logs = {}\n",
    "                    if gan_x is None or len(gan_x) == 0:\n",
    "                        # Handle data tensors support when no input given\n",
    "                        # step-size = 1 for data tensors\n",
    "                        batch_size = 1\n",
    "                    elif isinstance(gan_x, list):\n",
    "                        batch_size = gan_x[0].shape[0]\n",
    "                    elif isinstance(gan_x, dict):\n",
    "                        batch_size = list(gan_x.values())[0].shape[0]\n",
    "                    else:\n",
    "                        batch_size = gan_x.shape[0]\n",
    "                    batch_logs['batch'] = batch_index\n",
    "                    batch_logs['size'] = batch_size\n",
    "                    _callbacks.on_batch_begin(batch_index, batch_logs)\n",
    "                    for _ in range(self.disc_iters):\n",
    "                        gan_x, gan_y, gan_sample_weight, disc_x, disc_y, disc_sample_weight = generator_next()\n",
    "                        G_z = self.G.model.predict(gan_x)\n",
    "                        disc_outs= self.D.model.train_on_batch(disc_x, disc_y, sample_weight=disc_sample_weight, class_weight=class_weight)\n",
    "                    self.D.sequential.trainable= False\n",
    "                    self.D.model.trainable= False\n",
    "                    for _ in range(self.gen_iters):\n",
    "                        gan_x, gan_y, gan_sample_weight, disc_x, disc_y, disc_sample_weight = generator_next()\n",
    "                        # train generator: z->D(G(z)) real with discriminator is not trainable\n",
    "                        gan_outs = self.model.train_on_batch(gan_x, gan_y, sample_weight=gan_sample_weight, class_weight=class_weight)\n",
    "                    self.D.sequential.trainable= True\n",
    "                    self.D.model.trainable= True       \n",
    "                    \n",
    "                    disc_outs = utils.generic_utils.to_list(disc_outs)\n",
    "                    gan_outs = utils.generic_utils.to_list(gan_outs)\n",
    "                    \n",
    "                    for l, o in zip(out_labels, gan_outs+disc_outs):\n",
    "                        batch_logs[l] = o  \n",
    "                    \n",
    "                    _callbacks.on_batch_end(batch_index, batch_logs)\n",
    "\n",
    "                    batch_index += 1\n",
    "                    steps_done += 1\n",
    "                    \n",
    "                    # Epoch finished.\n",
    "                    if steps_done >= steps_per_epoch and do_validation:\n",
    "                        if gan_val_gen:\n",
    "                            gan_val_outs = self.model.evaluate_generator(\n",
    "                                gan_val_enqueuer_gen,\n",
    "                                gan_validation_steps,\n",
    "                                workers=0)\n",
    "                        if disc_val_gen:\n",
    "                            disc_val_outs = self.D.model.evaluate_generator(\n",
    "                                disc_val_enqueuer_gen,\n",
    "                                disc_validation_steps,\n",
    "                                workers=0)\n",
    "                        else:\n",
    "                            # No need for try/except because\n",
    "                            # data has already been validated.\n",
    "                            gan_val_outs = self.model.evaluate(\n",
    "                                gan_val_x, gan_val_y,\n",
    "                                batch_size=batch_size,\n",
    "                                sample_weight=gan_val_sample_weights,\n",
    "                                verbose=0)\n",
    "                            disc_val_outs = self.D.model.evaluate(\n",
    "                                disc_val_x, disc_val_y,\n",
    "                                batch_size=batch_size,\n",
    "                                sample_weight=disc_val_sample_weights,\n",
    "                                verbose=0)\n",
    "                        if self.eval_scores:\n",
    "                            is_mean, is_stdv, fid = self.get_eval_scores(splits=10, n_samples=self.n_samples//100)\n",
    "                            epoch_logs['IS_mean']=is_mean\n",
    "                            epoch_logs['IS_stdv']=is_stdv\n",
    "                            epoch_logs['FID']=fid\n",
    "                        gan_val_outs = utils.generic_utils.to_list(gan_val_outs)\n",
    "                        disc_val_outs = utils.generic_utils.to_list(disc_val_outs)\n",
    "                        # Same labels assumed.\n",
    "                        for l, o in zip(out_labels, gan_val_outs+disc_val_outs):\n",
    "                            epoch_logs['val_' + l] = o\n",
    "                    if gan_callback_model.stop_training:\n",
    "                        break\n",
    "                    if disc_callback_model.stop_training:\n",
    "                        break\n",
    "                        \n",
    "                    if self.checkpoint_interval:\n",
    "                        bool_checkpt = (steps_done % self.checkpoint_interval) == 0\n",
    "                    else:\n",
    "                        bool_checkpt = False\n",
    "                    if (steps_done >= steps_per_epoch or bool_checkpt) and self.PlotGenetaredSamples:\n",
    "                        if self.fixed_latent is None:\n",
    "                            noise = np.random.normal(0, 1, (self.grid[0]*self.grid[1],100))\n",
    "                        G_z= self.G.model.predict(noise)\n",
    "                        self.plot_generated_samples(G_z, grid=self.grid , imgsize=self.imgsize, img_range=self.target_scale,\n",
    "                                        cmap=(None if (self.G.output_shape[-1]) == 3 else 'gray'), logdir=self.logdir, img_name='epoch%d'%(epoch))\n",
    "                _callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "                epoch += 1\n",
    "                \n",
    "                if ModelCheckpoint:\n",
    "                    if not os.path.exists(os.path.join(logdir, 'models')): os.makedirs(os.path.join(logdir, 'models'))\n",
    "                    self.G.model.save_weights(os.path.join(logdir, 'models/gen_'+self.G.name+'.h5'))\n",
    "                    self.D.model.save_weights(os.path.join(logdir, 'models/disc_'+self.D.name+'.h5'))\n",
    "                \n",
    "                if gan_callback_model.stop_training:\n",
    "                    break\n",
    "                if disc_callback_model.stop_training:\n",
    "                    break\n",
    "                \n",
    "        finally:\n",
    "            try:\n",
    "                if gan_enqueuer is not None:\n",
    "                    gan_enqueuer.stop()\n",
    "                if disc_enqueuer is not None:\n",
    "                    disc_enqueuer.stop()\n",
    "            finally:\n",
    "                if gan_val_enqueuer is not None:\n",
    "                    gan_val_enqueuer.stop()\n",
    "                if disc_val_enqueuer is not None:\n",
    "                    disc_val_enqueuer.stop()\n",
    "\n",
    "        _callbacks.on_train_end()\n",
    "        return self.model.history, self.D.model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(GAN):\n",
    "    def __init__ (self, name='DCGAN', **kwargs):\n",
    "        super(DCGAN, self).__init__(name=name, **kwargs)\n",
    "        self.G = ConvNet_Up()\n",
    "        self.D = ConvNet()\n",
    "        \n",
    "        \n",
    "    def build_compile(self, input_shape, output_shape, loss, optimizer, metrics={'D':None}, pretrained_generator=None, pretrained_discriminator=None, **kwargs):\n",
    "        gen_io_shape, disc_io_shape = self.split_kwargs(input_shape= input_shape, output_shape=output_shape)\n",
    "        self.G.build(**gen_io_shape, len_io=1)\n",
    "        self.D.build(**disc_io_shape, len_io=2)\n",
    "        gen_compiler, disc_compiler = self.split_kwargs(loss= loss, optimizer=optimizer, metrics=metrics, **kwargs)\n",
    "        self.G.compile(**gen_compiler)\n",
    "        self.D.compile(**disc_compiler)\n",
    "        \n",
    "        self.D.sequential.trainable = False\n",
    "        self.D.model.trainable = False\n",
    "        \n",
    "        z = layers.Input(shape=self.G.input_shape)\n",
    "        G_z = self.G.model(z)\n",
    "        D_G_z = self.D.sequential(G_z)\n",
    "        self.model = models.Model(z, D_G_z)\n",
    "        if len(device_lib.list_local_devices()) >= 3:\n",
    "            self.model = multi_gpu_model(self.model, gpus=len(device_lib.list_local_devices())-1)\n",
    "        print(\"************************************GENERATOR_IN_GAN*************************************\")\n",
    "        self.model.summary()\n",
    "        self.model.compile(**gen_compiler)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_GP(GAN):\n",
    "    def __init__ (self, batch_size, name='WGAN_GP', **kwargs):\n",
    "        super(WGAN_GP, self).__init__(name=name, **kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.G = ConvNet_Up();\n",
    "        self.D = ConvNet_Critic(batch_size);\n",
    "        \n",
    "        \n",
    "    def build_compile(self, input_shape, output_shape, loss, optimizer, metrics={'D':None}, pretrained_generator=None, pretrained_discriminator=None, **kwargs):\n",
    "        gen_io_shape, disc_io_shape = self.split_kwargs(input_shape= input_shape, output_shape=output_shape)\n",
    "        self.G.build(**gen_io_shape, len_io=1)\n",
    "        self.D.build(**disc_io_shape, len_io=2)\n",
    "        gen_compiler, disc_compiler = self.split_kwargs(loss= loss, optimizer=optimizer, metrics=metrics, **kwargs)\n",
    "        self.G.compile(**gen_compiler)\n",
    "        self.D.compile(**disc_compiler)\n",
    "        \n",
    "        self.D.sequential.trainable = False\n",
    "        self.D.model.trainable = False\n",
    "        self.G.trainbale = True\n",
    "        z = layers.Input(shape=self.G.input_shape)\n",
    "        G_z = self.G.model(z)\n",
    "        D_G_z = self.D.sequential(G_z)\n",
    "        self.model = models.Model(z, D_G_z)\n",
    "        if len(device_lib.list_local_devices()) >= 3:\n",
    "            self.model = multi_gpu_model(self.model, gpus=len(device_lib.list_local_devices())-1)\n",
    "        print(\"************************************GENERATOR_IN_GAN*************************************\")\n",
    "        self.model.summary()\n",
    "        self.model.compile(**gen_compiler)\n",
    "        return self.model\n",
    "    \n",
    "    def train_generator_gan(self, x, batch_size, noise_shape, shift_fraction=0.):\n",
    "        Y_trash = np.ones(x.shape[0])\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, Y_trash, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, _ = generator.next()\n",
    "            ones = np.ones((np.shape(x_batch)[0], 1))\n",
    "            zeros = np.zeros((np.shape(x_batch)[0], 1))\n",
    "            noise = np.random.normal(0, 1, (np.shape(x_batch)[0],)+noise_shape)\n",
    "            G_noise = self.G.model.predict(np.random.normal(0, 1, (np.shape(x_batch)[0],)+noise_shape))\n",
    "            yield ({'G': noise, 'D': [x_batch, G_noise]}, {'G': np.append(-ones, ones, axis=-1), 'D': [np.append(-ones, ones, axis=-1), np.append(ones, -ones, axis=-1), np.append(zeros, zeros, axis=-1)]})\n",
    "\n",
    "    def test_generator_gan(self, x, noise_shape):\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        zeros = np.zeros((x.shape[0], 1))\n",
    "        noise = np.random.normal(0, 1, (x.shape[0],)+ noise_shape)\n",
    "        G_noise = self.G.model.predict(np.random.normal(0, 1, (x.shape[0],)+ noise_shape))\n",
    "        return ({'G': noise, 'D': [x, G_noise]}, {'G': np.append(-ones, ones, axis=-1), 'D': [np.append(-ones, ones, axis=-1), np.append(ones, -ones, axis=-1), np.append(zeros, zeros, axis=-1)]})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VCapsGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCapsGAN(GAN):\n",
    "    def __init__ (self, name='VCapsGAN', **kwargs):\n",
    "        super(VCapsGAN, self).__init__(name=name, **kwargs)\n",
    "        self.G = ConvNet_Up();\n",
    "        self.D = VCapsNet();\n",
    "        \n",
    "    \n",
    "    def build_compile(self, input_shape, output_shape, loss, optimizer, L1_n, L2_n, L2_dim, L3_dim, routing,  metrics={'D':None}, pretrained_generator=None, pretrained_discriminator=None, **kwargs):\n",
    "        gen_build_args, disc_build_args = self.split_kwargs(input_shape= input_shape, output_shape=output_shape,\n",
    "                                                           L1_n=L1_n, L2_n=L2_n, L2_dim=L2_dim, L3_dim=L3_dim, routing=routing)\n",
    "        self.G.build(**gen_build_args, len_io=1)\n",
    "        self.D.build(**disc_build_args, len_io=2)\n",
    "        gen_compile_args, disc_compile_args = self.split_kwargs(loss= loss, optimizer=optimizer, metrics=metrics, **kwargs)\n",
    "        self.D.compile(**disc_compile_args)\n",
    "        self.G.compile(**gen_compile_args)\n",
    "        \n",
    "        self.D.sequential.trainable = False\n",
    "        self.D.model.trainable = False\n",
    "        \n",
    "        z = layers.Input(shape=self.G.input_shape)\n",
    "        G_z = self.G.model(z)\n",
    "        D_G_z = self.D.sequential(G_z)\n",
    "        self.model = models.Model(z, D_G_z)\n",
    "        if len(device_lib.list_local_devices()) >= 3:\n",
    "            self.model = multi_gpu_model(self.model, gpus=len(device_lib.list_local_devices())-1)\n",
    "        print(\"************************************GENERATOR_IN_GAN*************************************\")\n",
    "        self.model.summary()\n",
    "        self.model.compile(**gen_compile_args)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCapsGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCapsGAN(GAN):\n",
    "    def __init__ (self, batch_size, name='MCapsGAN', **kwargs):\n",
    "        super(MCapsGAN, self).__init__(name=name, **kwargs)\n",
    "        self.G = ConvNet_Up();\n",
    "        self.D = MCapsNet(batch_size=batch_size);\n",
    "        \n",
    "    def build_compile(self, input_shape, output_shape, batch_size, n_samples, loss, optimizer, L1_n, L2_n, L3_n, L4_n, pose_shape={'D':[4,4]}, routing={'D':3}, decoder={'D':False},  metrics={'D':None}, pretrained_generator=None, pretrained_discriminator=None, **kwargs):\n",
    "        gen_build_args, disc_build_args = self.split_kwargs(input_shape= input_shape, output_shape=output_shape,\n",
    "                                                           L1_n=L1_n, L2_n=L2_n, L3_n=L3_n, L4_n=L4_n, pose_shape=pose_shape, routing=routing, decoder=decoder)\n",
    "        self.G.build(**gen_build_args, len_io=1)\n",
    "        self.D.build(**disc_build_args, len_io=2)\n",
    "        gen_compile_args, disc_compile_args = self.split_kwargs(loss= loss, optimizer=optimizer, metrics=metrics, **kwargs)\n",
    "        self.D.compile(batch_size=batch_size, n_samples=n_samples, **disc_compile_args)\n",
    "        self.G.compile(**gen_compile_args)\n",
    "        \n",
    "        \n",
    "        self.D.sequential.trainable = False\n",
    "        self.D.model.trainable = False\n",
    "        \n",
    "        z = layers.Input(shape=self.G.input_shape)\n",
    "        G_z = self.G.model(z)\n",
    "        D_G_z = self.D.sequential(G_z)\n",
    "        self.model = models.Model(input=z, output=D_G_z)\n",
    "        self.model = models.Model(z, D_G_z)\n",
    "        if len(device_lib.list_local_devices()) >= 3:\n",
    "            self.model = multi_gpu_model(self.model, gpus=len(device_lib.list_local_devices())-1)\n",
    "        print(\"************************************GENERATOR_IN_GAN*************************************\")\n",
    "        self.model.summary()\n",
    "        self.model.compile(**gen_compile_args)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint for every iteration => Training would be slow and checkpoint data would be huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValTensorBoard(cbks.TensorBoard):\n",
    "        def __init__(self, metrics=['acc', 'loss'] , log_dir = \"./logs\", **kwargs):\n",
    "            # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "            self.training_log_dir = os.path.join(log_dir, 'training')\n",
    "            super(TrainValTensorBoard, self).__init__(self.training_log_dir, **kwargs)\n",
    "            # Log the validation metrics to a separate subdirectory\n",
    "            self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "            self.step = 0\n",
    "            self.metrics = metrics\n",
    "            self.batch_writer = tf.summary.FileWriter(self.training_log_dir)\n",
    "\n",
    "        def set_model(self, model):\n",
    "            # Setup writer for validation metrics\n",
    "            self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "            super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            checkpt_dict= TRAIN[\"param\"][\"checkpoint\"]\n",
    "            # save trained models\n",
    "            if(checkpt_dict[\"models\"][\"save\"]):\n",
    "                models_dir=os.path.join(checkpt_dict[\"logdir\"], 'models')\n",
    "                DISCRIMINATOR[\"train\"].save_weights(os.path.join(models_dir, \"discriminator.h5\"))\n",
    "                if len(TRAIN[\"models_to_train\"]) == 2:\n",
    "                    GENERATOR[\"train\"].save_weights(os.path.join(models_dir, \"generator.h5\"))\n",
    "            logs = logs or {}\n",
    "            val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "            for name, value in val_logs.items():\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.val_writer.add_summary(summary, self.step)\n",
    "            self.val_writer.flush()\n",
    "\n",
    "            logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "            super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            for name, value in logs.items():\n",
    "                if name in self.metrics:\n",
    "                    summary = tf.Summary()\n",
    "                    summary_value = summary.value.add()\n",
    "                    summary_value.simple_value = value.item()\n",
    "                    summary_value.tag = name\n",
    "                    self.batch_writer.add_summary(summary, self.step) \n",
    "            self.batch_writer.flush()\n",
    "            self.step += 1\n",
    "            super(TrainValTensorBoard, self).on_batch_end(logs)\n",
    "\n",
    "        def on_train_end(self, logs=None):\n",
    "            super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "            self.val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disc_dict = DISCRIMINATOR[\"param\"]\n",
    "disc_net_dict = disc_dict[disc_dict[\"topology\"]]\n",
    "train_dict = TRAIN[\"param\"]\n",
    "checkpt_dict= train_dict[\"checkpoint\"]\n",
    "\n",
    "f = open(os.path.join(checkpt_dict[\"logdir\"], 'parameters.txt'),\"w\")\n",
    "f.write(\"DATASET:\"); f.write(\"\\n\"); f.write(str(DATASET)); f.write(\"\\n \\n\");\n",
    "f.write(\"GENERATOR:\"); f.write(\"\\n\"); f.write(str(GENERATOR)); f.write(\"\\n \\n\");\n",
    "f.write(\"DISCRIMINATOR:\"); f.write(\"\\n\"); f.write(str(DISCRIMINATOR)); f.write(\"\\n \\n\");\n",
    "f.write(\"COMBINED:\"); f.write(\"\\n\"); f.write(str(COMBINED)); f.write(\"\\n \\n\");\n",
    "f.write(\"TRAIN:\"); f.write(\"\\n\"); f.write(str(TRAIN));\n",
    "f.close()\n",
    "\n",
    "if len(TRAIN[\"models_to_train\"]) == 1:\n",
    "    if disc_dict[\"topology\"] is \"ConvNet\":\n",
    "        network =  ConvNet()\n",
    "        network.build(input_shape= disc_dict[\"inputs_shape\"], output_shape= disc_dict[\"output_shape\"])\n",
    "        network.compile(optimizer=disc_net_dict[\"optimizer\"], loss=network.loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    if disc_dict[\"topology\"] is \"VCapsNet\":\n",
    "        network =  VCapsNet()\n",
    "        if disc_net_dict[\"decoder\"]:\n",
    "            network.build(input_shape= disc_dict[\"inputs_shape\"], output_shape= disc_dict[\"output_shape\"],\n",
    "                          L1_n=disc_net_dict[\"L1_n\"],\n",
    "                          L2_n=disc_net_dict[\"L2_n\"],\n",
    "                          L2_dim=disc_net_dict[\"L2_dim\"],\n",
    "                          L3_dim=disc_net_dict[\"L3_dim\"],\n",
    "                          routing=disc_net_dict[\"routing_iters\"],\n",
    "                          decoder=disc_net_dict[\"decoder\"],\n",
    "                          L4_n=disc_net_dict[\"L4_n\"],\n",
    "                          L5_n=disc_net_dict[\"L5_n\"])\n",
    "            network.compile(optimizer=disc_net_dict[\"optimizer\"], loss=[network.loss_fn, 'mse'], metrics=['accuracy'])\n",
    "        else:\n",
    "            network.build(input_shape= disc_dict[\"inputs_shape\"], output_shape= disc_dict[\"output_shape\"],\n",
    "                          L1_n=disc_net_dict[\"L1_n\"],\n",
    "                          L2_n=disc_net_dict[\"L2_n\"],\n",
    "                          L2_dim=disc_net_dict[\"L2_dim\"],\n",
    "                          L3_dim=disc_net_dict[\"L3_dim\"],\n",
    "                          routing=disc_net_dict[\"routing_iters\"])\n",
    "            network.compile(optimizer=disc_net_dict[\"optimizer\"], loss=network.loss_fn, metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    if disc_dict[\"topology\"] is \"MCapsNet\":\n",
    "        network =  MCapsNet(batch_size=train_dict[\"batch_size\"])\n",
    "        network.build(input_shape= disc_dict[\"inputs_shape\"], output_shape= disc_dict[\"output_shape\"],\n",
    "                      L1_n=disc_net_dict[\"L1_n\"],\n",
    "                      L2_n=disc_net_dict[\"L2_n\"],\n",
    "                      L3_n=disc_net_dict[\"L3_n\"],\n",
    "                      L4_n=disc_net_dict[\"L4_n\"],\n",
    "                      routing=disc_net_dict[\"routing_iters\"],\n",
    "                      pose_shape=disc_net_dict[\"pose_shape\"])\n",
    "        network.compile(optimizer=disc_net_dict[\"optimizer\"], batch_size=train_dict[\"batch_size\"], n_samples=DATASET['train'].labels.shape[0], loss=network.loss_fn, metrics=['accuracy'])\n",
    "    network.fit(x=DATASET['train'].imgs, y=DATASET['train'].labels, batch_size=train_dict[\"batch_size\"], epochs=train_dict[\"epochs\"],\n",
    "               validation_data=[DATASET['test'].imgs, DATASET['test'].labels],\n",
    "               logdir=checkpt_dict[\"logdir\"], TensorBoard=False)\n",
    "\n",
    "if len(TRAIN[\"models_to_train\"]) == 2:\n",
    "    gen_dict = GENERATOR[\"param\"]\n",
    "    disc_dict = DISCRIMINATOR[\"param\"]\n",
    "    gan_dict = COMBINED[\"param\"]\n",
    "    if gan_dict[\"topology\"] is \"DCGAN\":\n",
    "        gen_net_dict = gen_dict[\"DeConvNet\"]\n",
    "        disc_net_dict = disc_dict[\"ConvNet\"]\n",
    "        network =  DCGAN()\n",
    "        network.build_compile(input_shape={'G':gen_dict[\"inputs_shape\"], 'D':disc_dict[\"inputs_shape\"]},\n",
    "                                     output_shape={'G':gen_dict[\"output_shape\"], 'D':disc_dict[\"output_shape\"]},\n",
    "                     loss={'G':network.D.loss_fn, 'D':[network.D.loss_fn, network.D.loss_fn]},\n",
    "                    optimizer={'G':gen_net_dict[\"optimizer\"], 'D':disc_net_dict[\"optimizer\"]},\n",
    "                              loss_weights={'D': [1, 1]}, metrics={'D':['accuracy']})\n",
    "        gen_history, disc_history = network.fit(x=DATASET['train'].imgs, batch_size=train_dict[\"batch_size\"], epochs=train_dict[\"epochs\"],\n",
    "               validation_data=[DATASET['test'].imgs, DATASET['test'].labels],\n",
    "               logdir=checkpt_dict[\"logdir\"], fixed_latent = True, checkpoint_interval= checkpt_dict[\"interval\"],\n",
    "                                               disc_iters = disc_net_dict[\"iters\"], gen_iters = gen_net_dict[\"iters\"],\n",
    "                                               load_weights={'G':TRAIN[\"trained_models\"]['G'], 'D':TRAIN[\"trained_models\"]['D']})\n",
    "    if gan_dict[\"topology\"] is \"WGAN_GP\":\n",
    "        gen_net_dict = gen_dict[\"DeConvNet\"]\n",
    "        disc_net_dict = disc_dict[\"Critic\"]\n",
    "        network =  WGAN_GP(batch_size=train_dict[\"batch_size\"])\n",
    "        network.build_compile(input_shape={'G':gen_dict[\"inputs_shape\"], 'D':disc_dict[\"inputs_shape\"]},\n",
    "                                     output_shape={'G':gen_dict[\"output_shape\"], 'D':disc_dict[\"output_shape\"]},\n",
    "                     loss={'G':network.D.loss_fn, 'D':[network.D.loss_fn, network.D.loss_fn]},\n",
    "                    optimizer={'G':disc_net_dict[\"optimizer\"], 'D':disc_net_dict[\"optimizer\"]},\n",
    "                              loss_weights={'D': [1, 1, 10]}, metrics={'D':['accuracy']})\n",
    "        gen_history, disc_history = network.fit(x=DATASET['train'].imgs, batch_size=train_dict[\"batch_size\"], epochs=train_dict[\"epochs\"],\n",
    "               validation_data=[DATASET['test'].imgs, DATASET['test'].labels],\n",
    "               logdir=checkpt_dict[\"logdir\"], fixed_latent = True, checkpoint_interval= checkpt_dict[\"interval\"],\n",
    "                                               disc_iters = disc_net_dict[\"iters\"], gen_iters = gen_net_dict[\"iters\"],\n",
    "                                               load_weights={'G':TRAIN[\"trained_models\"]['G'], 'D':TRAIN[\"trained_models\"]['D']})\n",
    "        \n",
    "       \n",
    "    if gan_dict[\"topology\"] is \"VCapsGAN\":\n",
    "        gen_net_dict = gen_dict[\"DeConvNet\"]\n",
    "        disc_net_dict = disc_dict[\"VCapsNet\"]\n",
    "        network = VCapsGAN()\n",
    "        network.build_compile(input_shape={'G':gen_dict[\"inputs_shape\"], 'D':disc_dict[\"inputs_shape\"]},\n",
    "                                     output_shape={'G':gen_dict[\"output_shape\"], 'D':disc_dict[\"output_shape\"]},\n",
    "                     loss={'G':network.D.loss_fn, 'D':[network.D.loss_fn, network.D.loss_fn]},\n",
    "                                  optimizer={'G':gen_net_dict[\"optimizer\"], 'D':disc_net_dict[\"optimizer\"]}, metrics={'D':['accuracy']},\n",
    "                             L1_n={'D':disc_net_dict[\"L1_n\"]}, L2_n={'D':disc_net_dict[\"L2_n\"]}, L2_dim={'D':disc_net_dict[\"L2_dim\"]}, L3_dim={'D':disc_net_dict[\"L3_dim\"]},\n",
    "                             routing = {'D':disc_net_dict[\"routing_iters\"]})\n",
    "        \n",
    "        gen_history, disc_history = network.fit(x=DATASET['train'].imgs, batch_size=train_dict[\"batch_size\"], epochs=train_dict[\"epochs\"],\n",
    "               validation_data=[DATASET['test'].imgs, DATASET['test'].labels],\n",
    "               logdir=checkpt_dict[\"logdir\"], fixed_latent = True, checkpoint_interval= checkpt_dict[\"interval\"], eval_scores=True,\n",
    "                                               load_weights={'G':TRAIN[\"trained_models\"]['G'], 'D':TRAIN[\"trained_models\"]['D']})\n",
    "    \n",
    "    if gan_dict[\"topology\"] is \"MCapsGAN\":\n",
    "        gen_net_dict = gen_dict[\"DeConvNet\"]\n",
    "        disc_net_dict = disc_dict[\"MCapsNet\"]\n",
    "        network = MCapsGAN(batch_size=train_dict[\"batch_size\"])\n",
    "        network.build_compile(input_shape={'G':gen_dict[\"inputs_shape\"], 'D':disc_dict[\"inputs_shape\"]},\n",
    "                                     output_shape={'G':gen_dict[\"output_shape\"], 'D':disc_dict[\"output_shape\"]},\n",
    "                     loss={'G':network.D.loss_fn, 'D':[network.D.loss_fn, network.D.loss_fn]},\n",
    "                                  optimizer={'G':gen_net_dict[\"optimizer\"], 'D':disc_net_dict[\"optimizer\"]}, metrics={'D':['accuracy']},\n",
    "                                  L1_n={'D':disc_net_dict[\"L1_n\"]},\n",
    "                                  L2_n={'D':disc_net_dict[\"L2_n\"]},\n",
    "                                  L3_n={'D':disc_net_dict[\"L3_n\"]},\n",
    "                                  L4_n={'D':disc_net_dict[\"L4_n\"]},\n",
    "                                  routing={'D':disc_net_dict[\"routing_iters\"]},\n",
    "                                  pose_shape={'D':disc_net_dict[\"pose_shape\"]},\n",
    "                             n_samples = DATASET['train'].imgs.shape[0],\n",
    "                             batch_size= train_dict[\"batch_size\"])\n",
    "        \n",
    "        gen_history, disc_history = network.fit(x=DATASET['train'].imgs, batch_size=train_dict[\"batch_size\"], epochs=train_dict[\"epochs\"],\n",
    "               validation_data=[DATASET['test'].imgs, DATASET['test'].labels],\n",
    "               logdir=checkpt_dict[\"logdir\"], fixed_latent = True, checkpoint_interval= checkpt_dict[\"interval\"],\n",
    "                                                load_weights={'G':TRAIN[\"trained_models\"]['G'], 'D':TRAIN[\"trained_models\"]['D']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the Inception Score and the FID after the training and plot 100 generated samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception Score & Fréchet Inception Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = network.get_eval_scores(splits=10, n_samples=1000)\n",
    "print(\"IS: mean {}, stdv {} \\n FID: {}\".format(score[0], score[1], score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Image Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_z= network.G.model.predict(np.random.normal(0, 1, (100,100)))\n",
    "network.plot_generated_samples(G_z, grid=network.grid , imgsize=network.imgsize, img_range=network.target_scale,\n",
    "                               cmap=(None if (network.G.output_shape[-1]) == 3 else 'gray'), logdir=network.logdir, img_name='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional visualizations for the discriminator as a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False predicted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(TRAIN[\"models_to_train\"]) != 2:\n",
    "    def show_false_predictions():\n",
    "        probabilities = DISCRIMINATOR['train'].predict(x=DATASET['test'].imgs)\n",
    "        predictions = probabilities.argmax(axis=-1)\n",
    "        labels = DATASET['test'].labels.argmax(axis=-1)\n",
    "        for i in range(len(probabilities)):\n",
    "            if predictions[i] != labels[i]:\n",
    "                print(\"prediction {} true {}\".format(predictions[i], labels[i]))\n",
    "                if len(DATASET['test'].imgs.shape[1:]) == 3:\n",
    "                    if DATASET['test'].imgs.shape[1:][2] == 1:\n",
    "                        plt.imshow(np.asarray(DATASET['test'].imgs[i][:, :, 0]), cmap='gray')\n",
    "                    else:\n",
    "                        plt.imshow(np.asarray(DATASET['test'].imgs[i][:, :, :]), cmap=None)\n",
    "                else:\n",
    "                    plt.imshow(np.asarray(DATASET['test'].imgs[i][:, :]), cmap='gray')\n",
    "                plt.show()\n",
    "    #show_false_predictions()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Desktop/CapsGAN/Main-2.ipynb",
    "public": false
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
